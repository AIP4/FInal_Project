{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40177, 22)\n",
      "Series([], dtype: float64)\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV', 'WW',\n",
      "       'CA_TOT', 'CA_MID', 'CT', 'VS', 'TS', 'IR', 'PM10', '지점', '위도', '경도',\n",
      "       'diff'],\n",
      "      dtype='object')\n",
      "(9485, 107)\n",
      "VV             0.031629\n",
      "WD_yanan       0.021086\n",
      "WS_yanan       0.021086\n",
      "TA_yanan       0.105430\n",
      "TD_yanan       0.274117\n",
      "HM_yanan       0.685293\n",
      "PS_yanan       0.031629\n",
      "PR             0.063258\n",
      "VV_tongliao    0.010543\n",
      "WD_tongliao    0.010543\n",
      "WS_tongliao    0.010543\n",
      "TA_tongliao    0.137059\n",
      "TD_tongliao    0.231945\n",
      "HM_tongliao    0.242488\n",
      "PS_tongliao    0.010543\n",
      "PR_tongliao    0.010543\n",
      "VV_qingdao     0.094887\n",
      "WD_qingdao     0.115973\n",
      "WS_qingdao     0.115973\n",
      "TA_qingdao     0.094887\n",
      "TD_qingdao     0.200316\n",
      "HM_qingdao     0.790722\n",
      "PS_qingdao     0.094887\n",
      "PR_qingdao     0.094887\n",
      "VV_chifeng     0.063258\n",
      "WD_chifeng     0.021086\n",
      "WS_chifeng     0.063258\n",
      "TA_chifeng     0.115973\n",
      "TD_chifeng     0.263574\n",
      "HM_chifeng     0.179230\n",
      "PS_chifeng     0.031629\n",
      "PR_chifeng     0.021086\n",
      "TA_dalian      0.042172\n",
      "TD_dalian      0.242488\n",
      "HM_dalian      0.042172\n",
      "dtype: float64\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV',\n",
      "       ...\n",
      "       'TD_dalian', 'HM_dalian', 'PS_dalian', 'PT_dalian', 'PR_dalian',\n",
      "       'RH_dalian', 'PM10_dalian', 'LON_dalian', 'LAT_dalian', 'diff'],\n",
      "      dtype='object', length=107)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# Load dataset\n",
    "region=\"andong\"\n",
    "path = f\"../../collect_data/filtered/kma/merged/kma_{region}_meta.csv\"\n",
    "\n",
    "# 2. CSV 파일 읽어서 데이터프레임으로 변환\n",
    "korea_data = pd.read_csv(path)\n",
    "china_data = concat_china_data(korea_data)\n",
    "\n",
    "korea_data = convert_timesteps(korea_data)\n",
    "print_missing_info(korea_data)\n",
    "\n",
    "china_data = convert_timesteps(china_data)\n",
    "print_missing_info(china_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국만\n",
    "feature importance 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\nimport numpy as np\\nfrom permutation import permutation\\nfrom MLP import train_and_evaluate\\n\\nselected_column=[\\'TE_005\\',\\'VS\\',\\'TE_02\\',\\'HM\\',\\'TA\\',\\'PS\\',\\'TD\\',\\'TE_01\\',\\'TS\\',\\'IR\\']\\n\\n# Features (X) and target (y)\\nX = korea_data[selected_column]\\n\\n# 결측값 처리하는 세가지 방안\\n#X.fillna(0, inplace=True)\\nX = X.fillna(X.mean())\\n#X.fillna(X.median(), inplace=True)\\n\\ny = korea_data[\\'PM10\\']\\n\\n# Train the model and get the necessary data\\nmean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\\n    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\\n)\\n\\n# Evaluate the model and calculate permutation importance\\nmean_mae, low_importance_features, features_with_scores = permutation(\\n    trained_model, X_train_val, y_train_val, X_test, y_test\\n)\\n\\n# Print the low importance features and their scores\\nprint(f\"Low Importance Features: {low_importance_features}\")\\nprint(f\"Features with Importance Scores: {features_with_scores}\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "import numpy as np\n",
    "from permutation import permutation\n",
    "from MLP import train_and_evaluate\n",
    "\n",
    "selected_column=['TE_005','VS','TE_02','HM','TA','PS','TD','TE_01','TS','IR']\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = korea_data[selected_column]\n",
    "\n",
    "# 결측값 처리하는 세가지 방안\n",
    "#X.fillna(0, inplace=True)\n",
    "X = X.fillna(X.mean())\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "\n",
    "y = korea_data['PM10']\n",
    "\n",
    "# Train the model and get the necessary data\n",
    "mean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\n",
    "    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\n",
    ")\n",
    "\n",
    "# Evaluate the model and calculate permutation importance\n",
    "mean_mae, low_importance_features, features_with_scores = permutation(\n",
    "    trained_model, X_train_val, y_train_val, X_test, y_test\n",
    ")\n",
    "\n",
    "# Print the low importance features and their scores\n",
    "print(f\"Low Importance Features: {low_importance_features}\")\n",
    "print(f\"Features with Importance Scores: {features_with_scores}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국 & 중국\n",
    "feature importance 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Mean Absolute Error: 13.064344596862792\n",
      "60/60 [==============================] - 0s 556us/step - loss: 172.7411 - mae: 9.4533\n",
      "Test Set Mean Absolute Error: 9.4533052444458\n",
      "Model Evaluation - Mean Absolute Error: 12011.6337890625\n",
      "60/60 [==============================] - 0s 422us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 456us/step\n",
      "60/60 [==============================] - 0s 456us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 414us/step\n",
      "60/60 [==============================] - 0s 483us/step\n",
      "60/60 [==============================] - 0s 430us/step\n",
      "60/60 [==============================] - 0s 452us/step\n",
      "60/60 [==============================] - 0s 518us/step\n",
      "60/60 [==============================] - 0s 487us/step\n",
      "60/60 [==============================] - 0s 489us/step\n",
      "60/60 [==============================] - 0s 417us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 562us/step\n",
      "60/60 [==============================] - 0s 444us/step\n",
      "60/60 [==============================] - 0s 479us/step\n",
      "60/60 [==============================] - 0s 480us/step\n",
      "60/60 [==============================] - 0s 519us/step\n",
      "60/60 [==============================] - 0s 526us/step\n",
      "60/60 [==============================] - 0s 494us/step\n",
      "60/60 [==============================] - 0s 454us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 444us/step\n",
      "60/60 [==============================] - 0s 470us/step\n",
      "60/60 [==============================] - 0s 437us/step\n",
      "60/60 [==============================] - 0s 446us/step\n",
      "60/60 [==============================] - 0s 439us/step\n",
      "60/60 [==============================] - 0s 452us/step\n",
      "60/60 [==============================] - 0s 486us/step\n",
      "60/60 [==============================] - 0s 452us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 415us/step\n",
      "60/60 [==============================] - 0s 391us/step\n",
      "60/60 [==============================] - 0s 409us/step\n",
      "60/60 [==============================] - 0s 403us/step\n",
      "60/60 [==============================] - 0s 458us/step\n",
      "60/60 [==============================] - 0s 473us/step\n",
      "60/60 [==============================] - 0s 523us/step\n",
      "60/60 [==============================] - 0s 465us/step\n",
      "60/60 [==============================] - 0s 446us/step\n",
      "60/60 [==============================] - 0s 404us/step\n",
      "60/60 [==============================] - 0s 409us/step\n",
      "60/60 [==============================] - 0s 461us/step\n",
      "60/60 [==============================] - 0s 388us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 404us/step\n",
      "60/60 [==============================] - 0s 382us/step\n",
      "60/60 [==============================] - 0s 453us/step\n",
      "60/60 [==============================] - 0s 509us/step\n",
      "60/60 [==============================] - 0s 426us/step\n",
      "60/60 [==============================] - 0s 400us/step\n",
      "60/60 [==============================] - 0s 409us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 429us/step\n",
      "60/60 [==============================] - 0s 437us/step\n",
      "60/60 [==============================] - 0s 393us/step\n",
      "60/60 [==============================] - 0s 404us/step\n",
      "60/60 [==============================] - 0s 403us/step\n",
      "60/60 [==============================] - 0s 406us/step\n",
      "60/60 [==============================] - 0s 429us/step\n",
      "60/60 [==============================] - 0s 429us/step\n",
      "60/60 [==============================] - 0s 413us/step\n",
      "60/60 [==============================] - 0s 384us/step\n",
      "60/60 [==============================] - 0s 474us/step\n",
      "60/60 [==============================] - 0s 418us/step\n",
      "60/60 [==============================] - 0s 426us/step\n",
      "60/60 [==============================] - 0s 439us/step\n",
      "60/60 [==============================] - 0s 460us/step\n",
      "60/60 [==============================] - 0s 426us/step\n",
      "60/60 [==============================] - 0s 408us/step\n",
      "60/60 [==============================] - 0s 373us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 384us/step\n",
      "60/60 [==============================] - 0s 428us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 424us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 399us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 382us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 440us/step\n",
      "60/60 [==============================] - 0s 442us/step\n",
      "60/60 [==============================] - 0s 425us/step\n",
      "60/60 [==============================] - 0s 442us/step\n",
      "60/60 [==============================] - 0s 382us/step\n",
      "60/60 [==============================] - 0s 431us/step\n",
      "60/60 [==============================] - 0s 403us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 517us/step\n",
      "60/60 [==============================] - 0s 413us/step\n",
      "60/60 [==============================] - 0s 432us/step\n",
      "60/60 [==============================] - 0s 485us/step\n",
      "60/60 [==============================] - 0s 526us/step\n",
      "60/60 [==============================] - 0s 473us/step\n",
      "60/60 [==============================] - 0s 420us/step\n",
      "60/60 [==============================] - 0s 491us/step\n",
      "Feature: PS, Importance: 161.48919686850058\n",
      "Feature: VS, Importance: 166.26350973231803\n",
      "Feature: HM, Importance: 16.59068097285217\n",
      "Feature: WD_yanan, Importance: -0.00756825306762039\n",
      "Feature: WD_qingdao, Importance: -0.5033028480815119\n",
      "Feature: WD_chifeng, Importance: 1.9956461164414576\n",
      "Feature: TA_dalian, Importance: -0.2455602024883774\n",
      "Feature: PR_dalian, Importance: -0.00023499108301621162\n",
      "Feature: WD_dalian, Importance: 0.29348704810490744\n",
      "Feature: TD_tongliao, Importance: 0.33084360743869184\n",
      "\n",
      "Top 10 Important Features (Sorted Descending by Importance Score):\n",
      "Feature: VS, Importance: 166.26350973231803\n",
      "Feature: PS, Importance: 161.48919686850058\n",
      "Feature: HM, Importance: 16.59068097285217\n",
      "Feature: WD_chifeng, Importance: 1.9956461164414576\n",
      "Feature: TD_tongliao, Importance: 0.33084360743869184\n",
      "Feature: WD_dalian, Importance: 0.29348704810490744\n",
      "Feature: PR_dalian, Importance: -0.00023499108301621162\n",
      "Feature: WD_yanan, Importance: -0.00756825306762039\n",
      "Feature: TA_dalian, Importance: -0.2455602024883774\n",
      "Feature: WD_qingdao, Importance: -0.5033028480815119\n",
      "Low Importance Features: ['WD_yanan', 'WD_qingdao', 'TA_dalian', 'PR_dalian']\n",
      "Features with Importance Scores: [('VS', 166.26350973231803), ('PS', 161.48919686850058), ('HM', 16.59068097285217), ('WD_chifeng', 1.9956461164414576), ('TD_tongliao', 0.33084360743869184), ('WD_dalian', 0.29348704810490744), ('PR_dalian', -0.00023499108301621162), ('WD_yanan', -0.00756825306762039), ('TA_dalian', -0.2455602024883774), ('WD_qingdao', -0.5033028480815119)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from permutation import permutation\n",
    "from MLP import train_and_evaluate\n",
    "\n",
    "selected_column=['PS','VS','HM','WD_yanan','WD_qingdao','WD_chifeng','TA_dalian','PR_dalian','WD_dalian','TD_tongliao']\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = china_data[selected_column]\n",
    "\n",
    "# 결측값 처리하는 세가지 방안\n",
    "#X.fillna(0, inplace=True)\n",
    "X = X.fillna(X.mean())\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "\n",
    "y = china_data['PM10']\n",
    "\n",
    "# Step 1: Train the model and get the necessary data\n",
    "mean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\n",
    "    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\n",
    ")\n",
    "\n",
    "# Step 2: Evaluate the model and calculate permutation importance\n",
    "mean_mae, low_importance_features, features_with_scores = permutation(\n",
    "    trained_model, X_train_val, y_train_val, X_test, y_test\n",
    ")\n",
    "\n",
    "# Print the low importance features and their scores\n",
    "print(f\"Low Importance Features: {low_importance_features}\")\n",
    "print(f\"Features with Importance Scores: {features_with_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
