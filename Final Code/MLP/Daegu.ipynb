{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40177, 22)\n",
      "Series([], dtype: float64)\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV', 'WW',\n",
      "       'CA_TOT', 'CA_MID', 'CT', 'VS', 'TS', 'IR', 'PM10', '지점', '위도', '경도',\n",
      "       'diff'],\n",
      "      dtype='object')\n",
      "(9486, 107)\n",
      "VV             0.031626\n",
      "WD_yanan       0.021084\n",
      "WS_yanan       0.021084\n",
      "TA_yanan       0.105419\n",
      "TD_yanan       0.274088\n",
      "HM_yanan       0.685220\n",
      "PS_yanan       0.031626\n",
      "PR             0.063251\n",
      "VV_tongliao    0.010542\n",
      "WD_tongliao    0.010542\n",
      "WS_tongliao    0.010542\n",
      "TA_tongliao    0.137044\n",
      "TD_tongliao    0.253004\n",
      "HM_tongliao    0.242463\n",
      "PS_tongliao    0.010542\n",
      "PR_tongliao    0.010542\n",
      "VV_qingdao     0.094877\n",
      "WD_qingdao     0.115960\n",
      "WS_qingdao     0.115960\n",
      "TA_qingdao     0.094877\n",
      "TD_qingdao     0.200295\n",
      "HM_qingdao     0.790639\n",
      "PS_qingdao     0.094877\n",
      "PR_qingdao     0.094877\n",
      "VV_chifeng     0.063251\n",
      "WD_chifeng     0.021084\n",
      "WS_chifeng     0.063251\n",
      "TA_chifeng     0.115960\n",
      "TD_chifeng     0.263546\n",
      "HM_chifeng     0.179211\n",
      "PS_chifeng     0.031626\n",
      "PR_chifeng     0.021084\n",
      "TA_dalian      0.042167\n",
      "TD_dalian      0.242463\n",
      "HM_dalian      0.042167\n",
      "dtype: float64\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV',\n",
      "       ...\n",
      "       'TD_dalian', 'HM_dalian', 'PS_dalian', 'PT_dalian', 'PR_dalian',\n",
      "       'RH_dalian', 'PM10_dalian', 'LON_dalian', 'LAT_dalian', 'diff'],\n",
      "      dtype='object', length=107)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# Load dataset\n",
    "region=\"daegu\"\n",
    "path = f\"../../collect_data/filtered/kma/merged/kma_{region}_meta.csv\"\n",
    "\n",
    "# 2. CSV 파일 읽어서 데이터프레임으로 변환\n",
    "korea_data = pd.read_csv(path)\n",
    "china_data = concat_china_data(korea_data)\n",
    "\n",
    "korea_data = convert_timesteps(korea_data)\n",
    "print_missing_info(korea_data)\n",
    "\n",
    "china_data = convert_timesteps(china_data)\n",
    "print_missing_info(china_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국만\n",
    "feature importance 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\nimport numpy as np\\nfrom permutation import permutation\\nfrom MLP import train_and_evaluate\\n\\nselected_column=[\\'TE_005\\',\\'VS\\',\\'TE_02\\',\\'HM\\',\\'TA\\',\\'PS\\',\\'TD\\',\\'TE_01\\',\\'TS\\',\\'IR\\']\\n\\n# Features (X) and target (y)\\nX = korea_data[selected_column]\\n\\n# 결측값 처리하는 세가지 방안\\n#X.fillna(0, inplace=True)\\nX = X.fillna(X.mean())\\n#X.fillna(X.median(), inplace=True)\\n\\ny = korea_data[\\'PM10\\']\\n\\n# Train the model and get the necessary data\\nmean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\\n    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\\n)\\n\\n# Evaluate the model and calculate permutation importance\\nmean_mae, low_importance_features, features_with_scores = permutation(\\n    trained_model, X_train_val, y_train_val, X_test, y_test\\n)\\n\\n# Print the low importance features and their scores\\nprint(f\"Low Importance Features: {low_importance_features}\")\\nprint(f\"Features with Importance Scores: {features_with_scores}\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "import numpy as np\n",
    "from permutation import permutation\n",
    "from MLP import train_and_evaluate\n",
    "\n",
    "selected_column=['TE_005','VS','TE_02','HM','TA','PS','TD','TE_01','TS','IR']\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = korea_data[selected_column]\n",
    "\n",
    "# 결측값 처리하는 세가지 방안\n",
    "#X.fillna(0, inplace=True)\n",
    "X = X.fillna(X.mean())\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "\n",
    "y = korea_data['PM10']\n",
    "\n",
    "# Train the model and get the necessary data\n",
    "mean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\n",
    "    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\n",
    ")\n",
    "\n",
    "# Evaluate the model and calculate permutation importance\n",
    "mean_mae, low_importance_features, features_with_scores = permutation(\n",
    "    trained_model, X_train_val, y_train_val, X_test, y_test\n",
    ")\n",
    "\n",
    "# Print the low importance features and their scores\n",
    "print(f\"Low Importance Features: {low_importance_features}\")\n",
    "print(f\"Features with Importance Scores: {features_with_scores}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국 & 중국\n",
    "feature importance 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Mean Absolute Error: 13.909407615661621\n",
      "60/60 [==============================] - 0s 587us/step - loss: 247.0259 - mae: 11.6680\n",
      "Test Set Mean Absolute Error: 11.66797161102295\n",
      "Model Evaluation - Mean Absolute Error: 9803.5966796875\n",
      "60/60 [==============================] - 0s 521us/step\n",
      "60/60 [==============================] - 0s 467us/step\n",
      "60/60 [==============================] - 0s 453us/step\n",
      "60/60 [==============================] - 0s 442us/step\n",
      "60/60 [==============================] - 0s 538us/step\n",
      "60/60 [==============================] - 0s 526us/step\n",
      "60/60 [==============================] - 0s 425us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 449us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 424us/step\n",
      "60/60 [==============================] - 0s 425us/step\n",
      "60/60 [==============================] - 0s 424us/step\n",
      "60/60 [==============================] - 0s 475us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 466us/step\n",
      "60/60 [==============================] - 0s 413us/step\n",
      "60/60 [==============================] - 0s 402us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 376us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 399us/step\n",
      "60/60 [==============================] - 0s 410us/step\n",
      "60/60 [==============================] - 0s 449us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 449us/step\n",
      "60/60 [==============================] - 0s 399us/step\n",
      "60/60 [==============================] - 0s 380us/step\n",
      "60/60 [==============================] - 0s 445us/step\n",
      "60/60 [==============================] - 0s 432us/step\n",
      "60/60 [==============================] - 0s 466us/step\n",
      "60/60 [==============================] - 0s 509us/step\n",
      "60/60 [==============================] - 0s 506us/step\n",
      "60/60 [==============================] - 0s 424us/step\n",
      "60/60 [==============================] - 0s 458us/step\n",
      "60/60 [==============================] - 0s 518us/step\n",
      "60/60 [==============================] - 0s 531us/step\n",
      "60/60 [==============================] - 0s 478us/step\n",
      "60/60 [==============================] - 0s 509us/step\n",
      "60/60 [==============================] - 0s 500us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 436us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 399us/step\n",
      "60/60 [==============================] - 0s 423us/step\n",
      "60/60 [==============================] - 0s 468us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 382us/step\n",
      "60/60 [==============================] - 0s 399us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 467us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 484us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 452us/step\n",
      "60/60 [==============================] - 0s 495us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 419us/step\n",
      "60/60 [==============================] - 0s 499us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 390us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 488us/step\n",
      "60/60 [==============================] - 0s 467us/step\n",
      "60/60 [==============================] - 0s 458us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 484us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 356us/step\n",
      "60/60 [==============================] - 0s 394us/step\n",
      "60/60 [==============================] - 0s 458us/step\n",
      "60/60 [==============================] - 0s 459us/step\n",
      "60/60 [==============================] - 0s 420us/step\n",
      "60/60 [==============================] - 0s 453us/step\n",
      "60/60 [==============================] - 0s 504us/step\n",
      "60/60 [==============================] - 0s 580us/step\n",
      "60/60 [==============================] - 0s 475us/step\n",
      "60/60 [==============================] - 0s 484us/step\n",
      "60/60 [==============================] - 0s 460us/step\n",
      "60/60 [==============================] - 0s 421us/step\n",
      "60/60 [==============================] - 0s 568us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 416us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 780us/step\n",
      "60/60 [==============================] - 0s 501us/step\n",
      "60/60 [==============================] - 0s 457us/step\n",
      "Feature: VS, Importance: 45.03060289640162\n",
      "Feature: PA, Importance: 35.45239199014232\n",
      "Feature: PS, Importance: 2.943377384973064\n",
      "Feature: TA, Importance: 3.5984816778882305\n",
      "Feature: TD_tongliao, Importance: 0.4273151188259362\n",
      "Feature: HM_dalian, Importance: 0.24289748534811223\n",
      "Feature: PM10_yanan, Importance: 0.24164507882687758\n",
      "Feature: PM10_dalian, Importance: 0.43754338487251515\n",
      "Feature: WD_chifeng, Importance: 0.116354581188898\n",
      "Feature: TD_qingdao, Importance: -0.04042894174508547\n",
      "\n",
      "Top 10 Important Features (Sorted Descending by Importance Score):\n",
      "Feature: VS, Importance: 45.03060289640162\n",
      "Feature: PA, Importance: 35.45239199014232\n",
      "Feature: TA, Importance: 3.5984816778882305\n",
      "Feature: PS, Importance: 2.943377384973064\n",
      "Feature: PM10_dalian, Importance: 0.43754338487251515\n",
      "Feature: TD_tongliao, Importance: 0.4273151188259362\n",
      "Feature: HM_dalian, Importance: 0.24289748534811223\n",
      "Feature: PM10_yanan, Importance: 0.24164507882687758\n",
      "Feature: WD_chifeng, Importance: 0.116354581188898\n",
      "Feature: TD_qingdao, Importance: -0.04042894174508547\n",
      "Low Importance Features: ['TD_qingdao']\n",
      "Features with Importance Scores: [('VS', 45.03060289640162), ('PA', 35.45239199014232), ('TA', 3.5984816778882305), ('PS', 2.943377384973064), ('PM10_dalian', 0.43754338487251515), ('TD_tongliao', 0.4273151188259362), ('HM_dalian', 0.24289748534811223), ('PM10_yanan', 0.24164507882687758), ('WD_chifeng', 0.116354581188898), ('TD_qingdao', -0.04042894174508547)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from permutation import permutation\n",
    "from MLP import train_and_evaluate\n",
    "\n",
    "selected_column=['VS','PA','PS','TA','TD_tongliao','HM_dalian','PM10_yanan','PM10_dalian','WD_chifeng','TD_qingdao']\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = china_data[selected_column]\n",
    "\n",
    "# 결측값 처리하는 세가지 방안\n",
    "#X.fillna(0, inplace=True)\n",
    "X = X.fillna(X.mean())\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "\n",
    "y = china_data['PM10']\n",
    "\n",
    "# Step 1: Train the model and get the necessary data\n",
    "mean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\n",
    "    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\n",
    ")\n",
    "\n",
    "# Step 2: Evaluate the model and calculate permutation importance\n",
    "mean_mae, low_importance_features, features_with_scores = permutation(\n",
    "    trained_model, X_train_val, y_train_val, X_test, y_test\n",
    ")\n",
    "\n",
    "# Print the low importance features and their scores\n",
    "print(f\"Low Importance Features: {low_importance_features}\")\n",
    "print(f\"Features with Importance Scores: {features_with_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
