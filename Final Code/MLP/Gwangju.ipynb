{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40140, 22)\n",
      "Series([], dtype: float64)\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV', 'WW',\n",
      "       'CA_TOT', 'CA_MID', 'CT', 'VS', 'TS', 'IR', 'PM10', '지점', '위도', '경도',\n",
      "       'diff'],\n",
      "      dtype='object')\n",
      "(9486, 107)\n",
      "VV             0.031626\n",
      "WD_yanan       0.021084\n",
      "WS_yanan       0.021084\n",
      "TA_yanan       0.105419\n",
      "TD_yanan       0.274088\n",
      "HM_yanan       0.685220\n",
      "PS_yanan       0.031626\n",
      "PR             0.063251\n",
      "VV_tongliao    0.010542\n",
      "WD_tongliao    0.010542\n",
      "WS_tongliao    0.010542\n",
      "TA_tongliao    0.137044\n",
      "TD_tongliao    0.253004\n",
      "HM_tongliao    0.242463\n",
      "PS_tongliao    0.010542\n",
      "PR_tongliao    0.010542\n",
      "VV_qingdao     0.094877\n",
      "WD_qingdao     0.115960\n",
      "WS_qingdao     0.115960\n",
      "TA_qingdao     0.094877\n",
      "TD_qingdao     0.200295\n",
      "HM_qingdao     0.790639\n",
      "PS_qingdao     0.094877\n",
      "PR_qingdao     0.094877\n",
      "VV_chifeng     0.063251\n",
      "WD_chifeng     0.021084\n",
      "WS_chifeng     0.063251\n",
      "TA_chifeng     0.115960\n",
      "TD_chifeng     0.263546\n",
      "HM_chifeng     0.179211\n",
      "PS_chifeng     0.031626\n",
      "PR_chifeng     0.021084\n",
      "TA_dalian      0.042167\n",
      "TD_dalian      0.242463\n",
      "HM_dalian      0.042167\n",
      "dtype: float64\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV',\n",
      "       ...\n",
      "       'TD_dalian', 'HM_dalian', 'PS_dalian', 'PT_dalian', 'PR_dalian',\n",
      "       'RH_dalian', 'PM10_dalian', 'LON_dalian', 'LAT_dalian', 'diff'],\n",
      "      dtype='object', length=107)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from utils import *\n",
    "\n",
    "# Load dataset\n",
    "region=\"gwangju\"\n",
    "path = f\"../../collect_data/filtered/kma/merged/kma_{region}_meta.csv\"\n",
    "\n",
    "# 2. CSV 파일 읽어서 데이터프레임으로 변환\n",
    "korea_data = pd.read_csv(path)\n",
    "china_data = concat_china_data(korea_data)\n",
    "\n",
    "korea_data = convert_timesteps(korea_data)\n",
    "print_missing_info(korea_data)\n",
    "\n",
    "china_data = convert_timesteps(china_data)\n",
    "print_missing_info(china_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국만\n",
    "feature importance 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import tensorflow as tf\\nimport numpy as np\\nfrom permutation import permutation\\nfrom MLP import train_and_evaluate\\n\\nselected_column=[\\'TE_005\\',\\'VS\\',\\'TE_02\\',\\'HM\\',\\'TA\\',\\'PS\\',\\'TD\\',\\'TE_01\\',\\'TS\\',\\'IR\\']\\n\\n# Features (X) and target (y)\\nX = korea_data[selected_column]\\n\\n# 결측값 처리하는 세가지 방안\\n#X.fillna(0, inplace=True)\\nX = X.fillna(X.mean())\\n#X.fillna(X.median(), inplace=True)\\n\\ny = korea_data[\\'PM10\\']\\n\\n# Train the model and get the necessary data\\nmean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\\n    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\\n)\\n\\n# Evaluate the model and calculate permutation importance\\nmean_mae, low_importance_features, features_with_scores = permutation(\\n    trained_model, X_train_val, y_train_val, X_test, y_test\\n)\\n\\n# Print the low importance features and their scores\\nprint(f\"Low Importance Features: {low_importance_features}\")\\nprint(f\"Features with Importance Scores: {features_with_scores}\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"import tensorflow as tf\n",
    "import numpy as np\n",
    "from permutation import permutation\n",
    "from MLP import train_and_evaluate\n",
    "\n",
    "selected_column=['TE_005','VS','TE_02','HM','TA','PS','TD','TE_01','TS','IR']\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = korea_data[selected_column]\n",
    "\n",
    "# 결측값 처리하는 세가지 방안\n",
    "#X.fillna(0, inplace=True)\n",
    "X = X.fillna(X.mean())\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "\n",
    "y = korea_data['PM10']\n",
    "\n",
    "# Train the model and get the necessary data\n",
    "mean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\n",
    "    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\n",
    ")\n",
    "\n",
    "# Evaluate the model and calculate permutation importance\n",
    "mean_mae, low_importance_features, features_with_scores = permutation(\n",
    "    trained_model, X_train_val, y_train_val, X_test, y_test\n",
    ")\n",
    "\n",
    "# Print the low importance features and their scores\n",
    "print(f\"Low Importance Features: {low_importance_features}\")\n",
    "print(f\"Features with Importance Scores: {features_with_scores}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 한국 & 중국\n",
    "feature importance 상위 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated Mean Absolute Error: 17.6470458984375\n",
      "60/60 [==============================] - 0s 568us/step - loss: 295.3405 - mae: 12.1905\n",
      "Test Set Mean Absolute Error: 12.19054889678955\n",
      "Model Evaluation - Mean Absolute Error: 10916.5166015625\n",
      "60/60 [==============================] - 0s 487us/step\n",
      "60/60 [==============================] - 0s 468us/step\n",
      "60/60 [==============================] - 0s 490us/step\n",
      "60/60 [==============================] - 0s 460us/step\n",
      "60/60 [==============================] - 0s 459us/step\n",
      "60/60 [==============================] - 0s 442us/step\n",
      "60/60 [==============================] - 0s 418us/step\n",
      "60/60 [==============================] - 0s 419us/step\n",
      "60/60 [==============================] - 0s 427us/step\n",
      "60/60 [==============================] - 0s 477us/step\n",
      "60/60 [==============================] - 0s 494us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 625us/step\n",
      "60/60 [==============================] - 0s 495us/step\n",
      "60/60 [==============================] - 0s 484us/step\n",
      "60/60 [==============================] - 0s 562us/step\n",
      "60/60 [==============================] - 0s 503us/step\n",
      "60/60 [==============================] - 0s 467us/step\n",
      "60/60 [==============================] - 0s 446us/step\n",
      "60/60 [==============================] - 0s 438us/step\n",
      "60/60 [==============================] - 0s 426us/step\n",
      "60/60 [==============================] - 0s 500us/step\n",
      "60/60 [==============================] - 0s 458us/step\n",
      "60/60 [==============================] - 0s 477us/step\n",
      "60/60 [==============================] - 0s 436us/step\n",
      "60/60 [==============================] - 0s 452us/step\n",
      "60/60 [==============================] - 0s 457us/step\n",
      "60/60 [==============================] - 0s 456us/step\n",
      "60/60 [==============================] - 0s 450us/step\n",
      "60/60 [==============================] - 0s 455us/step\n",
      "60/60 [==============================] - 0s 443us/step\n",
      "60/60 [==============================] - 0s 453us/step\n",
      "60/60 [==============================] - 0s 422us/step\n",
      "60/60 [==============================] - 0s 413us/step\n",
      "60/60 [==============================] - 0s 418us/step\n",
      "60/60 [==============================] - 0s 503us/step\n",
      "60/60 [==============================] - 0s 498us/step\n",
      "60/60 [==============================] - 0s 451us/step\n",
      "60/60 [==============================] - 0s 434us/step\n",
      "60/60 [==============================] - 0s 463us/step\n",
      "60/60 [==============================] - 0s 455us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 451us/step\n",
      "60/60 [==============================] - 0s 439us/step\n",
      "60/60 [==============================] - 0s 442us/step\n",
      "60/60 [==============================] - 0s 426us/step\n",
      "60/60 [==============================] - 0s 441us/step\n",
      "60/60 [==============================] - 0s 428us/step\n",
      "60/60 [==============================] - 0s 436us/step\n",
      "60/60 [==============================] - 0s 427us/step\n",
      "60/60 [==============================] - 0s 439us/step\n",
      "60/60 [==============================] - 0s 454us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 444us/step\n",
      "60/60 [==============================] - 0s 498us/step\n",
      "60/60 [==============================] - 0s 461us/step\n",
      "60/60 [==============================] - 0s 456us/step\n",
      "60/60 [==============================] - 0s 485us/step\n",
      "60/60 [==============================] - 0s 473us/step\n",
      "60/60 [==============================] - 0s 459us/step\n",
      "60/60 [==============================] - 0s 448us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 524us/step\n",
      "60/60 [==============================] - 0s 458us/step\n",
      "60/60 [==============================] - 0s 409us/step\n",
      "60/60 [==============================] - 0s 407us/step\n",
      "60/60 [==============================] - 0s 410us/step\n",
      "60/60 [==============================] - 0s 429us/step\n",
      "60/60 [==============================] - 0s 426us/step\n",
      "60/60 [==============================] - 0s 438us/step\n",
      "60/60 [==============================] - 0s 424us/step\n",
      "60/60 [==============================] - 0s 438us/step\n",
      "60/60 [==============================] - 0s 436us/step\n",
      "60/60 [==============================] - 0s 418us/step\n",
      "60/60 [==============================] - 0s 425us/step\n",
      "60/60 [==============================] - 0s 425us/step\n",
      "60/60 [==============================] - 0s 475us/step\n",
      "60/60 [==============================] - 0s 418us/step\n",
      "60/60 [==============================] - 0s 432us/step\n",
      "60/60 [==============================] - 0s 433us/step\n",
      "60/60 [==============================] - 0s 408us/step\n",
      "60/60 [==============================] - 0s 439us/step\n",
      "60/60 [==============================] - 0s 492us/step\n",
      "60/60 [==============================] - 0s 534us/step\n",
      "60/60 [==============================] - 0s 620us/step\n",
      "60/60 [==============================] - 0s 438us/step\n",
      "60/60 [==============================] - 0s 498us/step\n",
      "60/60 [==============================] - 0s 514us/step\n",
      "60/60 [==============================] - 0s 524us/step\n",
      "60/60 [==============================] - 0s 467us/step\n",
      "60/60 [==============================] - 0s 501us/step\n",
      "60/60 [==============================] - 0s 492us/step\n",
      "60/60 [==============================] - 0s 461us/step\n",
      "60/60 [==============================] - 0s 452us/step\n",
      "60/60 [==============================] - 0s 427us/step\n",
      "60/60 [==============================] - 0s 486us/step\n",
      "60/60 [==============================] - 0s 520us/step\n",
      "60/60 [==============================] - 0s 486us/step\n",
      "60/60 [==============================] - 0s 471us/step\n",
      "60/60 [==============================] - 0s 482us/step\n",
      "60/60 [==============================] - 0s 467us/step\n",
      "Feature: VS, Importance: 190.1800946769863\n",
      "Feature: PA, Importance: 56.27402037251104\n",
      "Feature: PS, Importance: 116.59657189282625\n",
      "Feature: HM, Importance: 16.15357066436791\n",
      "Feature: WD_qingdao, Importance: 2.392697734328067\n",
      "Feature: TS, Importance: 2.535972075193604\n",
      "Feature: WD_dalian, Importance: 1.7526012318397988\n",
      "Feature: TA, Importance: 1.6287194134560194\n",
      "Feature: PS_dalian, Importance: 0.07175261225602299\n",
      "Feature: TD_dalian, Importance: -0.38420353492347203\n",
      "\n",
      "Top 10 Important Features (Sorted Descending by Importance Score):\n",
      "Feature: VS, Importance: 190.1800946769863\n",
      "Feature: PS, Importance: 116.59657189282625\n",
      "Feature: PA, Importance: 56.27402037251104\n",
      "Feature: HM, Importance: 16.15357066436791\n",
      "Feature: TS, Importance: 2.535972075193604\n",
      "Feature: WD_qingdao, Importance: 2.392697734328067\n",
      "Feature: WD_dalian, Importance: 1.7526012318397988\n",
      "Feature: TA, Importance: 1.6287194134560194\n",
      "Feature: PS_dalian, Importance: 0.07175261225602299\n",
      "Feature: TD_dalian, Importance: -0.38420353492347203\n",
      "Low Importance Features: ['TD_dalian']\n",
      "Features with Importance Scores: [('VS', 190.1800946769863), ('PS', 116.59657189282625), ('PA', 56.27402037251104), ('HM', 16.15357066436791), ('TS', 2.535972075193604), ('WD_qingdao', 2.392697734328067), ('WD_dalian', 1.7526012318397988), ('TA', 1.6287194134560194), ('PS_dalian', 0.07175261225602299), ('TD_dalian', -0.38420353492347203)]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from permutation import permutation\n",
    "from MLP import train_and_evaluate\n",
    "\n",
    "selected_column=['VS','PA','PS','HM','WD_qingdao','TS','WD_dalian','TA','PS_dalian','TD_dalian']\n",
    "\n",
    "# Features (X) and target (y)\n",
    "X = china_data[selected_column]\n",
    "\n",
    "# 결측값 처리하는 세가지 방안\n",
    "#X.fillna(0, inplace=True)\n",
    "X = X.fillna(X.mean())\n",
    "#X.fillna(X.median(), inplace=True)\n",
    "\n",
    "y = china_data['PM10']\n",
    "\n",
    "# Step 1: Train the model and get the necessary data\n",
    "mean_mae, test_mae, trained_model, X_train_val, y_train_val, X_test, y_test = train_and_evaluate(\n",
    "    X, y, test_size=0.2, n_splits=5, epochs=100, batch_size=64\n",
    ")\n",
    "\n",
    "# Step 2: Evaluate the model and calculate permutation importance\n",
    "mean_mae, low_importance_features, features_with_scores = permutation(\n",
    "    trained_model, X_train_val, y_train_val, X_test, y_test\n",
    ")\n",
    "\n",
    "# Print the low importance features and their scores\n",
    "print(f\"Low Importance Features: {low_importance_features}\")\n",
    "print(f\"Features with Importance Scores: {features_with_scores}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
