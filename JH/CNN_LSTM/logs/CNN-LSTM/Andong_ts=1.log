2024-12-06 02:20:43,323 - Training model with Andong
2024-12-06 02:20:43,323 - Config: {'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'num_layers': 2, 'hidden_size': 128, 'window_size': 24, 'output_size': 1, 'dropout_prob': 0.2, 'patience': 10, 'out_channels': 16, 'kernel_size': 3, 'K': 1}
2024-12-06 02:20:43,324 - Model: FinedustCNNLSTM(
  (cnn): PM10CNN(
    (act): GELU(approximate='none')
    (conv_list): ModuleList(
      (0): Conv1d(4, 16, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (lstm): FinedustLSTM(
    (lstm): LSTMEmbedding(
      (lstm): LSTM(24, 128, num_layers=2, batch_first=True, dropout=0.2)
    )
    (fc1): Linear(in_features=128, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=1, bias=True)
    (act): GELU(approximate='none')
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
2024-12-06 02:20:43,324 - Model size: 227793

2024-12-06 02:20:43,324 - Train dataset: 8406
2024-12-06 02:20:43,324 - Valid dataset: 2102

2024-12-06 02:20:48,190 - Epoch 1/500, Train Loss: 27.9896, Val Loss: 23.4276
