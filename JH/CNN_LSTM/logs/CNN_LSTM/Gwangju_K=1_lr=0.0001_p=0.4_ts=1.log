2024-12-05 22:23:42,405 - Training model with Gwangju_K=1_lr=0.0001_p=0.4
2024-12-05 22:23:42,405 - Config: {'learning_rate': 0.0001, 'epochs': 500, 'batch_size': 32, 'num_layers': 2, 'hidden_size': 128, 'window_size': 24, 'output_size': 1, 'dropout_prob': 0.4, 'patience': 10, 'out_channels': 6, 'kernel_size': 3, 'K': 1}
2024-12-05 22:23:42,406 - Model: FinedustCNNLSTM(
  (cnn): PM10CNN(
    (act): GELU(approximate='none')
    (conv_list): ModuleList(
      (0): Conv1d(4, 6, kernel_size=(3,), stride=(1,), padding=(1,))
    )
  )
  (lstm): FinedustLSTM(
    (lstm): LSTMEmbedding(
      (lstm): LSTM(14, 128, num_layers=2, batch_first=True, dropout=0.4)
    )
    (fc1): Linear(in_features=128, out_features=128, bias=True)
    (fc2): Linear(in_features=128, out_features=1, bias=True)
    (act): GELU(approximate='none')
    (dropout): Dropout(p=0.4, inplace=False)
  )
)
2024-12-05 22:23:42,406 - Model size: 222543

2024-12-05 22:23:42,406 - Train dataset: 8404
2024-12-05 22:23:42,406 - Valid dataset: 2101

2024-12-05 22:23:43,542 - Epoch 1/500, Train Loss: 33.0926, Val Loss: 50.1978
2024-12-05 22:23:43,551 - Model saved with loss: 50.1978
2024-12-05 22:23:44,669 - Epoch 2/500, Train Loss: 26.5247, Val Loss: 49.7049
2024-12-05 22:23:44,678 - Model saved with loss: 49.7049
2024-12-05 22:23:45,791 - Epoch 3/500, Train Loss: 26.6593, Val Loss: 49.7165
2024-12-05 22:23:46,898 - Epoch 4/500, Train Loss: 26.6804, Val Loss: 49.7321
2024-12-05 22:23:48,006 - Epoch 5/500, Train Loss: 26.9492, Val Loss: 49.6832
2024-12-05 22:23:48,028 - Model saved with loss: 49.6832
2024-12-05 22:23:49,145 - Epoch 6/500, Train Loss: 26.7400, Val Loss: 49.7090
2024-12-05 22:23:50,270 - Epoch 7/500, Train Loss: 26.8363, Val Loss: 49.6918
2024-12-05 22:23:51,390 - Epoch 8/500, Train Loss: 26.6719, Val Loss: 49.7295
2024-12-05 22:23:52,549 - Epoch 9/500, Train Loss: 26.6943, Val Loss: 49.7425
2024-12-05 22:23:53,656 - Epoch 10/500, Train Loss: 26.8138, Val Loss: 49.7165
2024-12-05 22:23:54,765 - Epoch 11/500, Train Loss: 26.7939, Val Loss: 49.6999
2024-12-05 22:23:55,884 - Epoch 12/500, Train Loss: 26.8251, Val Loss: 49.6919
2024-12-05 22:23:57,002 - Epoch 13/500, Train Loss: 26.7996, Val Loss: 49.7278
2024-12-05 22:23:58,117 - Epoch 14/500, Train Loss: 26.6495, Val Loss: 49.6946
2024-12-05 22:23:59,219 - Epoch 15/500, Train Loss: 26.7526, Val Loss: 49.7192
2024-12-05 22:23:59,220 - Early stopping triggered after 10 epochs without improvement
2024-12-05 22:23:59,221 - Training completed with best loss: 49.6832
