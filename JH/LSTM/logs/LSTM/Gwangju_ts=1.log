2024-12-05 19:11:13,136 - Training model with Gwangju
2024-12-05 19:11:13,136 - Config: {'learning_rate': 0.0001, 'epochs': 200, 'batch_size': 32, 'num_layers': 2, 'hidden_size': 128, 'window_size': 24, 'output_size': 1, 'dropout': 0.1, 'patience': 10}
2024-12-05 19:11:13,136 - Model: FinedustLSTM(
  (lstm): LSTMEmbedding(
    (lstm): LSTM(8, 128, num_layers=2, batch_first=True, dropout=0.1)
    (fc1): Linear(in_features=128, out_features=384, bias=True)
    (fc2): Linear(in_features=384, out_features=128, bias=True)
    (act): GELU(approximate='none')
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (fc1): Linear(in_features=128, out_features=128, bias=True)
  (fc2): Linear(in_features=128, out_features=1, bias=True)
  (act): GELU(approximate='none')
  (dropout): Dropout(p=0.1, inplace=False)
)

2024-12-05 19:11:13,136 - Train dataset: 32080
2024-12-05 19:11:13,136 - Valid dataset: 8021

2024-12-05 19:11:15,146 - Epoch 1/200, Train Loss: 30.3775, Val Loss: 24.3033
2024-12-05 19:11:15,149 - Model saved with loss: 24.3033
2024-12-05 19:11:17,154 - Epoch 2/200, Train Loss: 29.4037, Val Loss: 24.2723
2024-12-05 19:11:17,157 - Model saved with loss: 24.2723
2024-12-05 19:11:19,158 - Epoch 3/200, Train Loss: 29.3252, Val Loss: 24.3024
2024-12-05 19:11:21,153 - Epoch 4/200, Train Loss: 29.3586, Val Loss: 24.4422
2024-12-05 19:11:23,144 - Epoch 5/200, Train Loss: 29.2659, Val Loss: 24.2836
2024-12-05 19:11:25,133 - Epoch 6/200, Train Loss: 29.3774, Val Loss: 24.3041
2024-12-05 19:11:27,148 - Epoch 7/200, Train Loss: 28.9108, Val Loss: 24.2548
2024-12-05 19:11:27,151 - Model saved with loss: 24.2548
2024-12-05 19:11:29,146 - Epoch 8/200, Train Loss: 29.1398, Val Loss: 24.0023
2024-12-05 19:11:29,149 - Model saved with loss: 24.0023
2024-12-05 19:11:31,130 - Epoch 9/200, Train Loss: 27.8519, Val Loss: 22.2044
2024-12-05 19:11:31,133 - Model saved with loss: 22.2044
2024-12-05 19:11:33,133 - Epoch 10/200, Train Loss: 27.5199, Val Loss: 21.8355
2024-12-05 19:11:33,136 - Model saved with loss: 21.8355
2024-12-05 19:11:35,140 - Epoch 11/200, Train Loss: 27.2310, Val Loss: 21.8318
2024-12-05 19:11:35,143 - Model saved with loss: 21.8318
2024-12-05 19:11:37,190 - Epoch 12/200, Train Loss: 27.0363, Val Loss: 21.7011
2024-12-05 19:11:37,192 - Model saved with loss: 21.7011
2024-12-05 19:11:39,245 - Epoch 13/200, Train Loss: 27.0999, Val Loss: 21.6421
2024-12-05 19:11:39,248 - Model saved with loss: 21.6421
2024-12-05 19:11:41,300 - Epoch 14/200, Train Loss: 26.8827, Val Loss: 21.6241
2024-12-05 19:11:41,303 - Model saved with loss: 21.6241
2024-12-05 19:11:43,357 - Epoch 15/200, Train Loss: 26.8700, Val Loss: 22.0341
2024-12-05 19:11:45,388 - Epoch 16/200, Train Loss: 26.7769, Val Loss: 21.2514
2024-12-05 19:11:45,391 - Model saved with loss: 21.2514
2024-12-05 19:11:47,443 - Epoch 17/200, Train Loss: 26.5006, Val Loss: 21.6641
2024-12-05 19:11:49,494 - Epoch 18/200, Train Loss: 26.5181, Val Loss: 21.1155
2024-12-05 19:11:49,496 - Model saved with loss: 21.1155
2024-12-05 19:11:51,549 - Epoch 19/200, Train Loss: 26.2873, Val Loss: 20.8790
2024-12-05 19:11:51,551 - Model saved with loss: 20.8790
2024-12-05 19:11:53,664 - Epoch 20/200, Train Loss: 26.0401, Val Loss: 21.4747
2024-12-05 19:11:55,719 - Epoch 21/200, Train Loss: 26.0532, Val Loss: 21.1493
2024-12-05 19:11:57,751 - Epoch 22/200, Train Loss: 26.0168, Val Loss: 21.2493
2024-12-05 19:11:59,818 - Epoch 23/200, Train Loss: 26.0997, Val Loss: 20.6171
2024-12-05 19:11:59,821 - Model saved with loss: 20.6171
2024-12-05 19:12:01,852 - Epoch 24/200, Train Loss: 25.8641, Val Loss: 20.6194
2024-12-05 19:12:03,918 - Epoch 25/200, Train Loss: 26.0739, Val Loss: 21.3766
2024-12-05 19:12:05,967 - Epoch 26/200, Train Loss: 25.7618, Val Loss: 22.2660
2024-12-05 19:12:08,050 - Epoch 27/200, Train Loss: 25.7764, Val Loss: 23.2514
2024-12-05 19:12:10,104 - Epoch 28/200, Train Loss: 25.6278, Val Loss: 20.3114
2024-12-05 19:12:10,107 - Model saved with loss: 20.3114
2024-12-05 19:12:12,188 - Epoch 29/200, Train Loss: 25.6266, Val Loss: 20.5773
2024-12-05 19:12:14,262 - Epoch 30/200, Train Loss: 25.2725, Val Loss: 20.2125
2024-12-05 19:12:14,264 - Model saved with loss: 20.2125
2024-12-05 19:12:16,338 - Epoch 31/200, Train Loss: 25.4393, Val Loss: 20.5389
2024-12-05 19:12:18,411 - Epoch 32/200, Train Loss: 25.8532, Val Loss: 20.2217
2024-12-05 19:12:20,487 - Epoch 33/200, Train Loss: 25.5386, Val Loss: 20.5461
2024-12-05 19:12:22,586 - Epoch 34/200, Train Loss: 24.7752, Val Loss: 20.5525
2024-12-05 19:12:24,611 - Epoch 35/200, Train Loss: 25.9238, Val Loss: 20.3416
2024-12-05 19:12:26,608 - Epoch 36/200, Train Loss: 26.4463, Val Loss: 20.6761
2024-12-05 19:12:28,628 - Epoch 37/200, Train Loss: 25.2591, Val Loss: 20.2208
2024-12-05 19:12:30,670 - Epoch 38/200, Train Loss: 25.2861, Val Loss: 20.5120
2024-12-05 19:12:32,688 - Epoch 39/200, Train Loss: 24.8693, Val Loss: 20.0092
2024-12-05 19:12:32,691 - Model saved with loss: 20.0092
2024-12-05 19:12:34,706 - Epoch 40/200, Train Loss: 24.8397, Val Loss: 20.0626
2024-12-05 19:12:36,745 - Epoch 41/200, Train Loss: 24.7317, Val Loss: 20.2366
2024-12-05 19:12:38,762 - Epoch 42/200, Train Loss: 24.9119, Val Loss: 20.4847
2024-12-05 19:12:40,762 - Epoch 43/200, Train Loss: 24.1853, Val Loss: 20.0322
2024-12-05 19:12:42,776 - Epoch 44/200, Train Loss: 24.4714, Val Loss: 21.6948
2024-12-05 19:12:44,788 - Epoch 45/200, Train Loss: 24.2151, Val Loss: 22.4740
2024-12-05 19:12:46,769 - Epoch 46/200, Train Loss: 24.5161, Val Loss: 19.9242
2024-12-05 19:12:46,772 - Model saved with loss: 19.9242
2024-12-05 19:12:48,814 - Epoch 47/200, Train Loss: 24.5564, Val Loss: 19.7680
2024-12-05 19:12:48,817 - Model saved with loss: 19.7680
2024-12-05 19:12:50,837 - Epoch 48/200, Train Loss: 23.7142, Val Loss: 19.9748
2024-12-05 19:12:52,859 - Epoch 49/200, Train Loss: 24.1512, Val Loss: 19.9158
2024-12-05 19:12:54,862 - Epoch 50/200, Train Loss: 24.0537, Val Loss: 19.6592
2024-12-05 19:12:54,865 - Model saved with loss: 19.6592
2024-12-05 19:12:56,907 - Epoch 51/200, Train Loss: 25.3580, Val Loss: 20.7361
2024-12-05 19:12:58,928 - Epoch 52/200, Train Loss: 24.6943, Val Loss: 20.0116
2024-12-05 19:13:00,956 - Epoch 53/200, Train Loss: 23.8922, Val Loss: 20.3265
2024-12-05 19:13:02,994 - Epoch 54/200, Train Loss: 23.7886, Val Loss: 20.2400
2024-12-05 19:13:05,017 - Epoch 55/200, Train Loss: 24.4157, Val Loss: 20.6088
2024-12-05 19:13:07,025 - Epoch 56/200, Train Loss: 24.7995, Val Loss: 19.9049
2024-12-05 19:13:09,013 - Epoch 57/200, Train Loss: 23.6750, Val Loss: 19.9756
2024-12-05 19:13:11,006 - Epoch 58/200, Train Loss: 24.0980, Val Loss: 20.6970
2024-12-05 19:13:12,993 - Epoch 59/200, Train Loss: 23.9938, Val Loss: 19.5168
2024-12-05 19:13:12,996 - Model saved with loss: 19.5168
2024-12-05 19:13:14,993 - Epoch 60/200, Train Loss: 23.9725, Val Loss: 20.1608
2024-12-05 19:13:16,988 - Epoch 61/200, Train Loss: 23.6038, Val Loss: 23.3401
2024-12-05 19:13:18,980 - Epoch 62/200, Train Loss: 24.5552, Val Loss: 20.2552
2024-12-05 19:13:20,990 - Epoch 63/200, Train Loss: 24.3800, Val Loss: 19.5372
2024-12-05 19:13:22,981 - Epoch 64/200, Train Loss: 23.3832, Val Loss: 20.5423
2024-12-05 19:13:24,965 - Epoch 65/200, Train Loss: 23.8855, Val Loss: 20.6251
2024-12-05 19:13:26,979 - Epoch 66/200, Train Loss: 24.0106, Val Loss: 19.9890
2024-12-05 19:13:29,012 - Epoch 67/200, Train Loss: 23.9221, Val Loss: 19.2508
2024-12-05 19:13:29,015 - Model saved with loss: 19.2508
2024-12-05 19:13:31,046 - Epoch 68/200, Train Loss: 23.8614, Val Loss: 19.5137
2024-12-05 19:13:33,108 - Epoch 69/200, Train Loss: 23.4156, Val Loss: 20.4969
2024-12-05 19:13:35,157 - Epoch 70/200, Train Loss: 24.4978, Val Loss: 20.0998
2024-12-05 19:13:37,198 - Epoch 71/200, Train Loss: 22.8663, Val Loss: 20.8340
2024-12-05 19:13:39,215 - Epoch 72/200, Train Loss: 23.0604, Val Loss: 22.6961
2024-12-05 19:13:41,229 - Epoch 73/200, Train Loss: 24.1852, Val Loss: 19.2914
2024-12-05 19:13:43,242 - Epoch 74/200, Train Loss: 23.6965, Val Loss: 22.1401
2024-12-05 19:13:45,278 - Epoch 75/200, Train Loss: 23.4287, Val Loss: 24.2997
2024-12-05 19:13:47,326 - Epoch 76/200, Train Loss: 25.2223, Val Loss: 19.6870
2024-12-05 19:13:49,389 - Epoch 77/200, Train Loss: 23.3147, Val Loss: 19.3380
2024-12-05 19:13:49,389 - Early stopping triggered after 10 epochs without improvement
2024-12-05 19:13:49,390 - Training completed with best loss: 19.2508
