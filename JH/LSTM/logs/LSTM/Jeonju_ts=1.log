2024-12-05 18:51:58,672 - Training model with Jeonju
2024-12-05 18:51:58,672 - Config: {'learning_rate': 0.001, 'epochs': 200, 'batch_size': 32, 'num_layers': 2, 'hidden_size': 256, 'window_size': 24, 'output_size': 1, 'dropout': 0.2, 'patience': 10}
2024-12-05 18:51:58,672 - Model: FinedustLSTM(
  (lstm): LSTMEmbedding(
    (lstm): LSTM(8, 256, num_layers=2, batch_first=True, dropout=0.2)
    (fc1): Linear(in_features=256, out_features=768, bias=True)
    (fc2): Linear(in_features=768, out_features=256, bias=True)
    (act): GELU(approximate='none')
    (dropout): Dropout(p=0.2, inplace=False)
  )
  (fc1): Linear(in_features=256, out_features=256, bias=True)
  (fc2): Linear(in_features=256, out_features=1, bias=True)
  (act): GELU(approximate='none')
  (dropout): Dropout(p=0.2, inplace=False)
)

2024-12-05 18:51:58,672 - Train dataset: 32108
2024-12-05 18:51:58,672 - Valid dataset: 8028

2024-12-05 18:52:01,811 - Epoch 1/200, Train Loss: 28.4139, Val Loss: 26.0042
2024-12-05 18:52:01,827 - Model saved with loss: 26.0042
2024-12-05 18:52:05,039 - Epoch 2/200, Train Loss: 28.1764, Val Loss: 24.9724
2024-12-05 18:52:05,055 - Model saved with loss: 24.9724
2024-12-05 18:52:08,250 - Epoch 3/200, Train Loss: 26.2917, Val Loss: 22.2936
2024-12-05 18:52:08,267 - Model saved with loss: 22.2936
2024-12-05 18:52:11,416 - Epoch 4/200, Train Loss: 24.9137, Val Loss: 22.1126
2024-12-05 18:52:11,433 - Model saved with loss: 22.1126
2024-12-05 18:52:14,580 - Epoch 5/200, Train Loss: 23.9370, Val Loss: 20.9239
2024-12-05 18:52:14,596 - Model saved with loss: 20.9239
2024-12-05 18:52:17,789 - Epoch 6/200, Train Loss: 23.2327, Val Loss: 19.9495
2024-12-05 18:52:17,805 - Model saved with loss: 19.9495
2024-12-05 18:52:20,953 - Epoch 7/200, Train Loss: 22.8977, Val Loss: 19.1193
2024-12-05 18:52:20,960 - Model saved with loss: 19.1193
2024-12-05 18:52:24,110 - Epoch 8/200, Train Loss: 22.5969, Val Loss: 19.0086
2024-12-05 18:52:24,126 - Model saved with loss: 19.0086
2024-12-05 18:52:27,273 - Epoch 9/200, Train Loss: 22.2286, Val Loss: 18.8600
2024-12-05 18:52:27,289 - Model saved with loss: 18.8600
2024-12-05 18:52:30,449 - Epoch 10/200, Train Loss: 21.9737, Val Loss: 19.0490
2024-12-05 18:52:33,597 - Epoch 11/200, Train Loss: 21.8363, Val Loss: 18.9507
2024-12-05 18:52:36,748 - Epoch 12/200, Train Loss: 21.9659, Val Loss: 19.4138
2024-12-05 18:52:39,892 - Epoch 13/200, Train Loss: 21.7471, Val Loss: 20.2207
2024-12-05 18:52:43,057 - Epoch 14/200, Train Loss: 21.9597, Val Loss: 18.1454
2024-12-05 18:52:43,073 - Model saved with loss: 18.1454
2024-12-05 18:52:46,216 - Epoch 15/200, Train Loss: 21.3556, Val Loss: 18.0661
2024-12-05 18:52:46,223 - Model saved with loss: 18.0661
2024-12-05 18:52:49,390 - Epoch 16/200, Train Loss: 21.2224, Val Loss: 20.7791
2024-12-05 18:52:52,533 - Epoch 17/200, Train Loss: 21.5774, Val Loss: 18.5639
2024-12-05 18:52:55,681 - Epoch 18/200, Train Loss: 21.5775, Val Loss: 18.3175
2024-12-05 18:52:58,794 - Epoch 19/200, Train Loss: 21.1310, Val Loss: 18.1879
2024-12-05 18:53:01,902 - Epoch 20/200, Train Loss: 21.3886, Val Loss: 18.2078
2024-12-05 18:53:04,990 - Epoch 21/200, Train Loss: 21.0696, Val Loss: 18.0059
2024-12-05 18:53:05,007 - Model saved with loss: 18.0059
2024-12-05 18:53:08,095 - Epoch 22/200, Train Loss: 21.1385, Val Loss: 26.4575
2024-12-05 18:53:11,191 - Epoch 23/200, Train Loss: 21.2829, Val Loss: 17.7872
2024-12-05 18:53:11,198 - Model saved with loss: 17.7872
2024-12-05 18:53:14,292 - Epoch 24/200, Train Loss: 20.4124, Val Loss: 18.1778
2024-12-05 18:53:17,413 - Epoch 25/200, Train Loss: 20.6236, Val Loss: 17.7568
2024-12-05 18:53:17,429 - Model saved with loss: 17.7568
2024-12-05 18:53:20,597 - Epoch 26/200, Train Loss: 20.1063, Val Loss: 17.6807
2024-12-05 18:53:20,614 - Model saved with loss: 17.6807
2024-12-05 18:53:23,825 - Epoch 27/200, Train Loss: 20.6561, Val Loss: 19.5584
2024-12-05 18:53:26,972 - Epoch 28/200, Train Loss: 21.2050, Val Loss: 18.1135
2024-12-05 18:53:30,126 - Epoch 29/200, Train Loss: 20.3323, Val Loss: 18.7563
2024-12-05 18:53:33,278 - Epoch 30/200, Train Loss: 20.3478, Val Loss: 17.4736
2024-12-05 18:53:33,295 - Model saved with loss: 17.4736
2024-12-05 18:53:36,505 - Epoch 31/200, Train Loss: 20.2711, Val Loss: 18.1210
2024-12-05 18:53:39,663 - Epoch 32/200, Train Loss: 19.8737, Val Loss: 18.4709
2024-12-05 18:53:42,816 - Epoch 33/200, Train Loss: 20.1475, Val Loss: 17.2582
2024-12-05 18:53:42,833 - Model saved with loss: 17.2582
2024-12-05 18:53:46,044 - Epoch 34/200, Train Loss: 19.5658, Val Loss: 17.2134
2024-12-05 18:53:46,051 - Model saved with loss: 17.2134
2024-12-05 18:53:49,217 - Epoch 35/200, Train Loss: 19.3675, Val Loss: 17.3393
2024-12-05 18:53:52,368 - Epoch 36/200, Train Loss: 19.4850, Val Loss: 21.0986
2024-12-05 18:53:55,483 - Epoch 37/200, Train Loss: 20.2976, Val Loss: 18.1059
2024-12-05 18:53:58,602 - Epoch 38/200, Train Loss: 20.3703, Val Loss: 17.1294
2024-12-05 18:53:58,618 - Model saved with loss: 17.1294
2024-12-05 18:54:01,730 - Epoch 39/200, Train Loss: 19.9457, Val Loss: 17.1387
2024-12-05 18:54:04,858 - Epoch 40/200, Train Loss: 20.3492, Val Loss: 17.5948
2024-12-05 18:54:07,966 - Epoch 41/200, Train Loss: 19.8083, Val Loss: 16.9323
2024-12-05 18:54:07,982 - Model saved with loss: 16.9323
2024-12-05 18:54:11,100 - Epoch 42/200, Train Loss: 19.3538, Val Loss: 18.2774
2024-12-05 18:54:14,205 - Epoch 43/200, Train Loss: 20.5355, Val Loss: 17.7144
2024-12-05 18:54:17,325 - Epoch 44/200, Train Loss: 20.2764, Val Loss: 18.2492
2024-12-05 18:54:20,436 - Epoch 45/200, Train Loss: 19.5352, Val Loss: 16.6403
2024-12-05 18:54:20,453 - Model saved with loss: 16.6403
2024-12-05 18:54:23,569 - Epoch 46/200, Train Loss: 19.4750, Val Loss: 16.9257
2024-12-05 18:54:26,672 - Epoch 47/200, Train Loss: 19.1954, Val Loss: 16.7287
2024-12-05 18:54:29,793 - Epoch 48/200, Train Loss: 18.9754, Val Loss: 17.6368
2024-12-05 18:54:32,902 - Epoch 49/200, Train Loss: 19.7146, Val Loss: 18.1672
2024-12-05 18:54:36,023 - Epoch 50/200, Train Loss: 19.9735, Val Loss: 16.6941
2024-12-05 18:54:39,126 - Epoch 51/200, Train Loss: 19.3342, Val Loss: 16.6991
2024-12-05 18:54:42,263 - Epoch 52/200, Train Loss: 19.1277, Val Loss: 19.1633
2024-12-05 18:54:45,373 - Epoch 53/200, Train Loss: 18.8125, Val Loss: 17.2012
2024-12-05 18:54:48,512 - Epoch 54/200, Train Loss: 20.4904, Val Loss: 21.3068
2024-12-05 18:54:51,657 - Epoch 55/200, Train Loss: 19.8567, Val Loss: 17.0258
2024-12-05 18:54:51,657 - Early stopping triggered after 10 epochs without improvement
2024-12-05 18:54:51,658 - Training completed with best loss: 16.6403
