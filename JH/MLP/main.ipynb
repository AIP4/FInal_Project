{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 13223,
     "status": "ok",
     "timestamp": 1733376404928,
     "user": {
      "displayName": "한준호",
      "userId": "12870242508044632368"
     },
     "user_tz": -540
    },
    "id": "eyh9pZnrfP0X"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from utils import set_logger\n",
    "from dataset import MLPDataset\n",
    "from model import MLP\n",
    "from utils import prepare_data, get_model_size\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import logging\n",
    "from interpolate import simple_interpolate\n",
    "import numpy as np\n",
    "from preprocess import minmax_scaling\n",
    "from train import train\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733376404929,
     "user": {
      "displayName": "한준호",
      "userId": "12870242508044632368"
     },
     "user_tz": -540
    },
    "id": "Lx5HNBDMfP0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 500,\n",
    "    \"batch_size\": 32,\n",
    "    \"output_size\": 1,\n",
    "    \"dropout_prob\": 0.2,\n",
    "    \"patience\": 10,\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iaam3qEXfP0e"
   },
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han07301/ai_project/JH/MLP/interpolate.py:41: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data = data.interpolate(method='linear')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.8889,  0.1064,  0.2118,  0.3671,  0.5900,  0.0848,  0.2484,  0.1375,\n",
       "         46.0000]),\n",
       " tensor([46.]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = \"Andong\"\n",
    "\n",
    "if region == \"Jeonju\":\n",
    "  columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"IX\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "else:\n",
    "  columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "df = prepare_data(region.lower(), columns_to_remove)\n",
    "df = simple_interpolate(df, method=\"linear\")\n",
    "df, scaler = minmax_scaling(df)\n",
    "\n",
    "dataset = MLPDataset(df)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 768191,
     "status": "error",
     "timestamp": 1733377174842,
     "user": {
      "displayName": "한준호",
      "userId": "12870242508044632368"
     },
     "user_tz": -540
    },
    "id": "rU8d51tsfP0g",
    "outputId": "0522ba2c-077b-4169-ddec-1577993ad7fb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/han07301/ai_project/JH/MLP/interpolate.py:41: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data = data.interpolate(method='linear')\n",
      "  0%|          | 0/500 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_pickle.Pickler' object attribute 'persistent_id' is read-only",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     17\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m'\u001b[39m], shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m model \u001b[38;5;241m=\u001b[39m MLP(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mfeature_columns),\n\u001b[1;32m     20\u001b[0m             dropout_prob\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 22\u001b[0m total_preds, losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLSTM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m pred_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(total_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     29\u001b[0m val_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([y \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m val_dataset])\n",
      "File \u001b[0;32m~/ai_project/JH/MLP/train.py:100\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, valid_dataset, feature_columns, region, model_name, config, device, log_suffix)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_loss \u001b[38;5;241m<\u001b[39m best_loss:\n\u001b[1;32m     99\u001b[0m     best_loss \u001b[38;5;241m=\u001b[39m val_loss\n\u001b[0;32m--> 100\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mregion\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved with loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    102\u001b[0m     epochs_without_improvement \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/practice/lib/python3.13/site-packages/torch/serialization.py:850\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 850\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/practice/lib/python3.13/site-packages/torch/serialization.py:1087\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1085\u001b[0m data_buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[1;32m   1086\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[0;32m-> 1087\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpersistent_id\u001b[49m \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[1;32m   1088\u001b[0m pickler\u001b[38;5;241m.\u001b[39mdump(obj)\n\u001b[1;32m   1089\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_pickle.Pickler' object attribute 'persistent_id' is read-only"
     ]
    }
   ],
   "source": [
    "regions = [\"Andong\", \"Seoul\", \"Jeonju\", \"Daegu\", \"Gwangju\"]\n",
    "\n",
    "pred_list, loss_list = [], []\n",
    "\n",
    "for region in regions:\n",
    "  if region == \"Jeonju\":\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"IX\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "  else:\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "  df = prepare_data(region.lower(), columns_to_remove)\n",
    "  df = simple_interpolate(df, method=\"linear\")\n",
    "  df, scaler = minmax_scaling(df)\n",
    "\n",
    "  dataset = MLPDataset(df)\n",
    "  train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "  train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "  model = MLP(input_size=len(dataset.feature_columns),\n",
    "              dropout_prob=config[\"dropout_prob\"]).to(device)\n",
    "\n",
    "  total_preds, losses = train(model,\n",
    "                              train_dataset,\n",
    "                              val_dataset,\n",
    "                              dataset.feature_columns,\n",
    "                              region, \"LSTM\", config,\n",
    "                              device)\n",
    "  pred_y = np.concatenate(total_preds, axis=0)\n",
    "  val_y = np.concatenate([y for x, y in val_dataset])\n",
    "\n",
    "  pred_list.append((pred_y, val_y))\n",
    "  loss_list.append(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전주와 광주에서 underfitting 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hidden_size => 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "H8CN5qe2O6aq"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"epochs\": 200,\n",
    "    \"batch_size\": 32,\n",
    "    \"num_layers\": 2,\n",
    "    \"hidden_size\": 128,\n",
    "    \"window_size\": 24,\n",
    "    \"output_size\": 1,\n",
    "    \"dropout\": 0.1,\n",
    "    \"patience\": 10,\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "OygyGJM3Os_x"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangwon/nlplab_leaderboard2/Junho/JH/LSTM/interpolate.py:41: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data = data.interpolate(method='linear')\n",
      "  0%|          | 1/200 [00:02<06:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Train Loss: 30.3775, Val Loss: 24.3033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/200 [00:04<06:37,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200, Train Loss: 29.4037, Val Loss: 24.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 3/200 [00:06<06:35,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200, Train Loss: 29.3252, Val Loss: 24.3024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 4/200 [00:08<06:32,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200, Train Loss: 29.3586, Val Loss: 24.4422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▎         | 5/200 [00:10<06:29,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/200, Train Loss: 29.2659, Val Loss: 24.2836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 6/200 [00:11<06:26,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/200, Train Loss: 29.3774, Val Loss: 24.3041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 7/200 [00:14<06:26,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200, Train Loss: 28.9108, Val Loss: 24.2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 8/200 [00:16<06:24,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/200, Train Loss: 29.1398, Val Loss: 24.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 9/200 [00:17<06:21,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/200, Train Loss: 27.8519, Val Loss: 22.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 10/200 [00:19<06:19,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Train Loss: 27.5199, Val Loss: 21.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 11/200 [00:22<06:18,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/200, Train Loss: 27.2310, Val Loss: 21.8318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 12/200 [00:24<06:18,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/200, Train Loss: 27.0363, Val Loss: 21.7011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 13/200 [00:26<06:19,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/200, Train Loss: 27.0999, Val Loss: 21.6421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 14/200 [00:28<06:18,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200, Train Loss: 26.8827, Val Loss: 21.6241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:30<06:17,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/200, Train Loss: 26.8700, Val Loss: 22.0341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 16/200 [00:32<06:15,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200, Train Loss: 26.7769, Val Loss: 21.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 17/200 [00:34<06:13,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/200, Train Loss: 26.5006, Val Loss: 21.6641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 18/200 [00:36<06:12,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200, Train Loss: 26.5181, Val Loss: 21.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 19/200 [00:38<06:10,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/200, Train Loss: 26.2873, Val Loss: 20.8790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 20/200 [00:40<06:12,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200, Train Loss: 26.0401, Val Loss: 21.4747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 21/200 [00:42<06:09,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200, Train Loss: 26.0532, Val Loss: 21.1493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 22/200 [00:44<06:05,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/200, Train Loss: 26.0168, Val Loss: 21.2493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 23/200 [00:46<06:04,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200, Train Loss: 26.0997, Val Loss: 20.6171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 24/200 [00:48<06:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/200, Train Loss: 25.8641, Val Loss: 20.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 25/200 [00:50<05:59,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/200, Train Loss: 26.0739, Val Loss: 21.3766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 26/200 [00:52<05:57,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/200, Train Loss: 25.7618, Val Loss: 22.2660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 27/200 [00:54<05:56,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/200, Train Loss: 25.7764, Val Loss: 23.2514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 28/200 [00:56<05:54,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/200, Train Loss: 25.6278, Val Loss: 20.3114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 29/200 [00:59<05:53,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200, Train Loss: 25.6266, Val Loss: 20.5773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 30/200 [01:01<05:51,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/200, Train Loss: 25.2725, Val Loss: 20.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 31/200 [01:03<05:49,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/200, Train Loss: 25.4393, Val Loss: 20.5389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32/200 [01:05<05:48,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/200, Train Loss: 25.8532, Val Loss: 20.2217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 33/200 [01:07<05:46,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/200, Train Loss: 25.5386, Val Loss: 20.5461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 34/200 [01:09<05:45,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/200, Train Loss: 24.7752, Val Loss: 20.5525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 35/200 [01:11<05:40,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200, Train Loss: 25.9238, Val Loss: 20.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 36/200 [01:13<05:35,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/200, Train Loss: 26.4463, Val Loss: 20.6761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 37/200 [01:15<05:31,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/200, Train Loss: 25.2591, Val Loss: 20.2208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 38/200 [01:17<05:30,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/200, Train Loss: 25.2861, Val Loss: 20.5120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 39/200 [01:19<05:27,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/200, Train Loss: 24.8693, Val Loss: 20.0092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 40/200 [01:21<05:24,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/200, Train Loss: 24.8397, Val Loss: 20.0626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 41/200 [01:23<05:22,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/200, Train Loss: 24.7317, Val Loss: 20.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 42/200 [01:25<05:20,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/200, Train Loss: 24.9119, Val Loss: 20.4847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 43/200 [01:27<05:16,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/200, Train Loss: 24.1853, Val Loss: 20.0322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 44/200 [01:29<05:14,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/200, Train Loss: 24.4714, Val Loss: 21.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▎       | 45/200 [01:31<05:12,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/200, Train Loss: 24.2151, Val Loss: 22.4740\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 46/200 [01:33<05:08,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/200, Train Loss: 24.5161, Val Loss: 19.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 47/200 [01:35<05:08,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/200, Train Loss: 24.5564, Val Loss: 19.7680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 48/200 [01:37<05:06,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/200, Train Loss: 23.7142, Val Loss: 19.9748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 49/200 [01:39<05:04,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/200, Train Loss: 24.1512, Val Loss: 19.9158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 50/200 [01:41<05:02,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200, Train Loss: 24.0537, Val Loss: 19.6592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 51/200 [01:43<05:01,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/200, Train Loss: 25.3580, Val Loss: 20.7361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 52/200 [01:45<04:59,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/200, Train Loss: 24.6943, Val Loss: 20.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 53/200 [01:47<04:57,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/200, Train Loss: 23.8922, Val Loss: 20.3265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 54/200 [01:49<04:56,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/200, Train Loss: 23.7886, Val Loss: 20.2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 55/200 [01:51<04:53,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/200, Train Loss: 24.4157, Val Loss: 20.6088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 56/200 [01:53<04:51,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/200, Train Loss: 24.7995, Val Loss: 19.9049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 57/200 [01:55<04:47,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200, Train Loss: 23.6750, Val Loss: 19.9756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 58/200 [01:57<04:44,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200, Train Loss: 24.0980, Val Loss: 20.6970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 59/200 [01:59<04:42,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200, Train Loss: 23.9938, Val Loss: 19.5168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 60/200 [02:01<04:39,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/200, Train Loss: 23.9725, Val Loss: 20.1608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 61/200 [02:03<04:37,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/200, Train Loss: 23.6038, Val Loss: 23.3401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 62/200 [02:05<04:35,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200, Train Loss: 24.5552, Val Loss: 20.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 63/200 [02:07<04:34,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/200, Train Loss: 24.3800, Val Loss: 19.5372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 64/200 [02:09<04:31,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/200, Train Loss: 23.3832, Val Loss: 20.5423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▎      | 65/200 [02:11<04:29,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/200, Train Loss: 23.8855, Val Loss: 20.6251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 66/200 [02:13<04:27,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200, Train Loss: 24.0106, Val Loss: 19.9890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 67/200 [02:15<04:27,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/200, Train Loss: 23.9221, Val Loss: 19.2508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 68/200 [02:17<04:26,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/200, Train Loss: 23.8614, Val Loss: 19.5137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 69/200 [02:19<04:25,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200, Train Loss: 23.4156, Val Loss: 20.4969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 70/200 [02:22<04:24,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/200, Train Loss: 24.4978, Val Loss: 20.0998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 71/200 [02:24<04:22,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/200, Train Loss: 22.8663, Val Loss: 20.8340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 72/200 [02:26<04:19,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/200, Train Loss: 23.0604, Val Loss: 22.6961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 73/200 [02:28<04:17,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200, Train Loss: 24.1852, Val Loss: 19.2914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 74/200 [02:30<04:14,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200, Train Loss: 23.6965, Val Loss: 22.1401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 75/200 [02:32<04:13,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/200, Train Loss: 23.4287, Val Loss: 24.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [02:34<04:12,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/200, Train Loss: 25.2223, Val Loss: 19.6870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 76/200 [02:36<04:14,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/200, Train Loss: 23.3147, Val Loss: 19.3380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "region = \"Gwangju\"\n",
    "\n",
    "if region == \"Jeonju\":\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"IX\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "else:\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "    \n",
    "df = prepare_data(region.lower(), columns_to_remove)\n",
    "df = simple_interpolate(df, method=\"linear\")\n",
    "df, scaler = minmax_scaling(df)\n",
    "\n",
    "dataset = FinedustDataset(df,\n",
    "                          window_size=config[\"window_size\"],\n",
    "                          prediction_length=config[\"output_size\"],\n",
    "                          time_window=1)\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "model = FinedustLSTM(input_size=len(dataset.feature_columns),\n",
    "                            hidden_size=config['hidden_size'],\n",
    "                            num_layers=config['num_layers'],\n",
    "                            output_size=config['output_size'],\n",
    "                            dropout_prob=config['dropout']).to(device)\n",
    "\n",
    "total_preds, losses = train(model,\n",
    "                            train_dataset,\n",
    "                            val_dataset,\n",
    "                            dataset.feature_columns,\n",
    "                            region, \"LSTM\", config,\n",
    "                            device)\n",
    "pred_y = np.concatenate(total_preds, axis=0)\n",
    "val_y = np.concatenate([y for x, y in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = \"Gwangju\"\n",
    "\n",
    "if region == \"Jeonju\":\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"IX\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "else:\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "    \n",
    "df = prepare_data(region.lower(), columns_to_remove)\n",
    "df = simple_interpolate(df, method=\"linear\")\n",
    "df, scaler = minmax_scaling(df)\n",
    "\n",
    "dataset = FinedustDataset(df,\n",
    "                          window_size=config[\"window_size\"],\n",
    "                          prediction_length=config[\"output_size\"],\n",
    "                          time_window=1)\n",
    "train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "model = FinedustLSTM(input_size=len(dataset.feature_columns),\n",
    "                            hidden_size=config['hidden_size'],\n",
    "                            num_layers=config['num_layers'],\n",
    "                            output_size=config['output_size'],\n",
    "                            dropout_prob=config['dropout']).to(device)\n",
    "\n",
    "total_preds, losses = train(model,\n",
    "                            train_dataset,\n",
    "                            val_dataset,\n",
    "                            dataset.feature_columns,\n",
    "                            region, \"LSTM\", config,\n",
    "                            device)\n",
    "pred_y = np.concatenate(total_preds, axis=0)\n",
    "val_y = np.concatenate([y for x, y in val_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1733371043851,
     "user": {
      "displayName": "한준호",
      "userId": "12870242508044632368"
     },
     "user_tz": -540
    },
    "id": "4tzoey323sJG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def compute_permutation_importance(model, val_loader, feature_columns, device, loss_fn=nn.L1Loss()):\n",
    "    model.eval()\n",
    "\n",
    "    # Compute baseline performance\n",
    "    baseline_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            preds = model(x)\n",
    "            loss = loss_fn(preds, y)\n",
    "            baseline_loss += loss.item() * x.size(0)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "            all_targets.append(y.cpu().numpy())\n",
    "\n",
    "    baseline_loss /= len(val_loader.dataset)\n",
    "    print(f\"Baseline MSE Loss: {baseline_loss:.4f}\")\n",
    "\n",
    "    # Initialize importance dictionary\n",
    "    feature_importances = {}\n",
    "\n",
    "    # Convert validation data to a single tensor for manipulation\n",
    "    all_x = []\n",
    "    all_y = []\n",
    "    for x, y in val_loader:\n",
    "        all_x.append(x)\n",
    "        all_y.append(y)\n",
    "    all_x = torch.cat(all_x, dim=0).to(device)\n",
    "    all_y = torch.cat(all_y, dim=0).to(device)\n",
    "\n",
    "    for i, feature in enumerate(feature_columns):\n",
    "        # Shuffle the i-th feature\n",
    "        x_permuted = deepcopy(all_x)\n",
    "        # Shuffle along the batch dimension\n",
    "        perm = torch.randperm(x_permuted.size(0))\n",
    "        x_permuted[:, :, i] = x_permuted[perm, :, i]\n",
    "\n",
    "        # Compute loss with permuted feature\n",
    "        preds = model(x_permuted)\n",
    "        loss = loss_fn(preds, all_y).item()\n",
    "\n",
    "        # Importance is the increase in loss\n",
    "        importance = loss - baseline_loss\n",
    "        feature_importances[feature] = importance\n",
    "        print(f\"Feature: {feature}, Permutation Importance: {importance:.4f}\")\n",
    "\n",
    "    return feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andong', 'Seoul', 'Jeonju', 'Daegu']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 351013,
     "status": "ok",
     "timestamp": 1733372285708,
     "user": {
      "displayName": "한준호",
      "userId": "12870242508044632368"
     },
     "user_tz": -540
    },
    "id": "rjZ-K-Ru4pvs",
    "outputId": "6471e0a7-88a6-440a-fdf9-b24a257a35d5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangwon/nlplab_leaderboard2/Junho/JH/LSTM/interpolate.py:41: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data = data.interpolate(method='linear')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE Loss: 6.4699\n",
      "Feature: WD, Permutation Importance: 3.6131\n",
      "Feature: WS, Permutation Importance: 3.5572\n",
      "Feature: TA, Permutation Importance: 4.3083\n",
      "Feature: TD, Permutation Importance: 1.9318\n",
      "Feature: HM, Permutation Importance: 7.6094\n",
      "Feature: PV, Permutation Importance: 4.6644\n",
      "Feature: VS, Permutation Importance: 12.2706\n",
      "Feature: TS, Permutation Importance: 3.0322\n",
      "Feature importances saved to importance/LSTM/Andong.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangwon/nlplab_leaderboard2/Junho/JH/LSTM/interpolate.py:41: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data = data.interpolate(method='linear')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE Loss: 13.5851\n",
      "Feature: WD, Permutation Importance: 6.2550\n",
      "Feature: WS, Permutation Importance: 3.6059\n",
      "Feature: TA, Permutation Importance: 1.1206\n",
      "Feature: TD, Permutation Importance: 1.1049\n",
      "Feature: HM, Permutation Importance: 5.1800\n",
      "Feature: PV, Permutation Importance: 5.0815\n",
      "Feature: VS, Permutation Importance: 10.2841\n",
      "Feature: TS, Permutation Importance: 1.3686\n",
      "Feature: TE_005, Permutation Importance: 0.7640\n",
      "Feature: TE_01, Permutation Importance: 4.8736\n",
      "Feature: TE_02, Permutation Importance: 5.2185\n",
      "Feature: TE_03, Permutation Importance: 1.7073\n",
      "Feature importances saved to importance/LSTM/Seoul.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sangwon/nlplab_leaderboard2/Junho/JH/LSTM/interpolate.py:41: FutureWarning: DataFrame.interpolate with object dtype is deprecated and will raise in a future version. Call obj.infer_objects(copy=False) before interpolating instead.\n",
      "  data = data.interpolate(method='linear')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FinedustLSTM:\n\tsize mismatch for lstm.lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 8]) from checkpoint, the shape in current model is torch.Size([512, 8]).\n\tsize mismatch for lstm.lstm.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for lstm.lstm.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.lstm.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.lstm.weight_ih_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for lstm.lstm.weight_hh_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for lstm.lstm.bias_ih_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.lstm.bias_hh_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.fc1.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for lstm.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for lstm.fc2.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([128, 384]).\n\tsize mismatch for lstm.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 27\u001b[0m\n\u001b[1;32m     21\u001b[0m model \u001b[38;5;241m=\u001b[39m FinedustLSTM(input_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mfeature_columns),\n\u001b[1;32m     22\u001b[0m                             hidden_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhidden_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     23\u001b[0m                             num_layers\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_layers\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     24\u001b[0m                             output_size\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_size\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     25\u001b[0m                             dropout_prob\u001b[38;5;241m=\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdropout\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/LSTM/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mregion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m feature_importances \u001b[38;5;241m=\u001b[39m compute_permutation_importance(model, val_loader, dataset\u001b[38;5;241m.\u001b[39mfeature_columns, device)\n",
      "File \u001b[0;32m~/anaconda3/envs/student/lib/python3.12/site-packages/torch/nn/modules/module.py:2153\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2149\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2150\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2154\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FinedustLSTM:\n\tsize mismatch for lstm.lstm.weight_ih_l0: copying a param with shape torch.Size([1024, 8]) from checkpoint, the shape in current model is torch.Size([512, 8]).\n\tsize mismatch for lstm.lstm.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for lstm.lstm.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.lstm.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.lstm.weight_ih_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for lstm.lstm.weight_hh_l1: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for lstm.lstm.bias_ih_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.lstm.bias_hh_l1: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for lstm.fc1.weight: copying a param with shape torch.Size([768, 256]) from checkpoint, the shape in current model is torch.Size([384, 128]).\n\tsize mismatch for lstm.fc1.bias: copying a param with shape torch.Size([768]) from checkpoint, the shape in current model is torch.Size([384]).\n\tsize mismatch for lstm.fc2.weight: copying a param with shape torch.Size([256, 768]) from checkpoint, the shape in current model is torch.Size([128, 384]).\n\tsize mismatch for lstm.fc2.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc1.weight: copying a param with shape torch.Size([256, 256]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for fc2.weight: copying a param with shape torch.Size([1, 256]) from checkpoint, the shape in current model is torch.Size([1, 128])."
     ]
    }
   ],
   "source": [
    "output_dir = f\"importance/LSTM\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for region in regions:\n",
    "  if region == \"Jeonju\":\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"IX\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "  else:\n",
    "    columns_to_remove = [\"CA_TOT\", \"CA_MID\", \"STN\", \"IR\", \"PA\", \"PS\", \"지점\", \"위도\", \"경도\"]\n",
    "  df = prepare_data(region.lower(), columns_to_remove)\n",
    "  df = simple_interpolate(df, method=\"linear\")\n",
    "  df, scaler = minmax_scaling(df)\n",
    "\n",
    "  dataset = FinedustDataset(df,\n",
    "                            window_size=config[\"window_size\"],\n",
    "                            prediction_length=config[\"output_size\"],\n",
    "                            time_window=1)\n",
    "  train_dataset, val_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "  train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "  val_loader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "  if region == \"Jeonju\":\n",
    "    config[\"hidden_size\"] = 256\n",
    "  else:\n",
    "    config[\"hidden_size\"] = 128\n",
    "  model = FinedustLSTM(input_size=len(dataset.feature_columns),\n",
    "                              hidden_size=config['hidden_size'],\n",
    "                              num_layers=config['num_layers'],\n",
    "                              output_size=config['output_size'],\n",
    "                              dropout_prob=config['dropout']).to(device)\n",
    "  save_path = f\"models/LSTM/{region}.pth\"\n",
    "  model.load_state_dict(torch.load(save_path))\n",
    "  model.to(device)\n",
    "\n",
    "  feature_importances = compute_permutation_importance(model, val_loader, dataset.feature_columns, device)\n",
    "  output_path = f\"{output_dir}/{region}.txt\"\n",
    "\n",
    "  with open(output_path, \"w\") as f:\n",
    "    f.write(\"Feature Importances:\\n\")\n",
    "    for feature, importance in sorted(feature_importances.items(), key=lambda x: x[1], reverse=True):\n",
    "        f.write(f\"{feature}: {importance:.4f}\\n\")\n",
    "  print(f\"Feature importances saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J66n_axxfP0h"
   },
   "source": [
    "# Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CQ3OlL0_uaYW"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import TimeSeriesTransformerForPrediction\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction.from_pretrained(\n",
    "    \"huggingface/time-series-transformer-tourism-monthly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7q0RSAoluheZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(val_y[:1000], label=\"val_y\", color=\"blue\")\n",
    "plt.plot(pred_y[:1000], label=\"pred_y\", color=\"orange\")\n",
    "plt.title(f\"MLP (loss={np.min(losses[:, 1]): .2f})\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "student",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
