{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hJwQfT5t0txd"
   },
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQkNZJ5z0tjT",
    "outputId": "90225be9-db7e-4756-e64f-409fb3e58bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40175, 26)\n",
      "Series([], dtype: float64)\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV', 'WW',\n",
      "       'CA_TOT', 'CA_MID', 'CT', 'VS', 'TS', 'TE_005', 'TE_01', 'TE_02',\n",
      "       'TE_03', 'IR', 'PM10', '지점', '위도', '경도', 'diff'],\n",
      "      dtype='object')\n",
      "                       TM    STN    WD   WS      PA      PS   TA    TD    HM  \\\n",
      "0     2018-01-01 00:00:00  108.0   0.0  0.0     0.0     0.0  0.0   0.0   0.0   \n",
      "1     2018-01-01 01:00:00  108.0   0.0  0.0     0.0     0.0  0.0   0.0   0.0   \n",
      "2     2018-01-01 02:00:00  108.0   0.0  0.0     0.0     0.0  0.0   0.0   0.0   \n",
      "3     2018-01-01 03:00:00  108.0   0.0  0.0     0.0     0.0  0.0   0.0   0.0   \n",
      "4     2018-01-01 04:00:00  108.0   0.0  0.0     0.0     0.0  0.0   0.0   0.0   \n",
      "...                   ...    ...   ...  ...     ...     ...  ...   ...   ...   \n",
      "40170 2022-11-30 20:00:00  108.0  27.0  3.1  1022.6  1033.8 -5.8  13.4  55.0   \n",
      "40171 2022-11-30 21:00:00  108.0  27.0  4.2  1022.6  1033.8 -6.7  12.9  61.0   \n",
      "40172 2022-11-30 22:00:00  108.0  32.0  4.3  1023.1  1034.4 -7.4  14.4  57.0   \n",
      "40173 2022-11-30 23:00:00  108.0  34.0  3.6  1023.3  1034.6 -7.9  14.9  57.0   \n",
      "40174 2022-12-01 00:00:00  108.0  34.0  3.4  1023.0  1034.3 -8.0  15.4  55.0   \n",
      "\n",
      "        PV  ... TE_005  TE_01  TE_02 TE_03   IR  PM10   지점       위도        경도  \\\n",
      "0      0.0  ...    0.0    0.0    0.0   0.0  0.0  34.0  108  37.5714  126.9658   \n",
      "1      0.0  ...    0.0    0.0    0.0   0.0  0.0  37.0  108  37.5714  126.9658   \n",
      "2      0.0  ...    0.0    0.0    0.0   0.0  0.0  29.0  108  37.5714  126.9658   \n",
      "3      0.0  ...    0.0    0.0    0.0   0.0  0.0  29.0  108  37.5714  126.9658   \n",
      "4      0.0  ...    0.0    0.0    0.0   0.0  0.0  35.0  108  37.5714  126.9658   \n",
      "...    ...  ...    ...    ...    ...   ...  ...   ...  ...      ...       ...   \n",
      "40170  2.2  ...    4.2    4.6    6.1   8.2  3.0  13.0  108  37.5714  126.9658   \n",
      "40171  2.3  ...    4.0    4.5    6.0   8.1  3.0  14.0  108  37.5714  126.9658   \n",
      "40172  2.0  ...    3.8    4.3    5.9   8.0  3.0  19.0  108  37.5714  126.9658   \n",
      "40173  1.9  ...    3.6    4.1    5.8   8.0  3.0  10.0  108  37.5714  126.9658   \n",
      "40174  1.8  ...    3.4    4.0    5.7   7.9  3.0  10.0  108  37.5714  126.9658   \n",
      "\n",
      "       diff  \n",
      "0       3.0  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       1.0  \n",
      "4       1.0  \n",
      "...     ...  \n",
      "40170   1.0  \n",
      "40171   1.0  \n",
      "40172   1.0  \n",
      "40173   1.0  \n",
      "40174   1.0  \n",
      "\n",
      "[40175 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from utils import *\n",
    "\n",
    "# Load dataset\n",
    "region=\"seoul\"\n",
    "path = f\"../../collect_data/filtered/kma/merged/kma_{region}_meta.csv\"\n",
    "\n",
    "# 2. CSV 파일 읽어서 데이터프레임으로 변환\n",
    "korea_data = pd.read_csv(path)\n",
    "\n",
    "# Select relevant columns for prediction\n",
    "#selected_columns = ['STN','TM', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'CA_TOT', 'CA_MID', 'VS', 'TS', 'TE_005', 'TE_01', 'TE_02','TE_03', 'PV', 'PM10']\n",
    "#korea_data = korean_df[selected_columns]\n",
    "\n",
    "# Sort by time\n",
    "#korea_data = korea_data.sort_values('TM').reset_index(drop=True)\n",
    "\n",
    "korea_data = convert_timesteps(korea_data)\n",
    "print_missing_info(korea_data)\n",
    "\n",
    "print(korea_data)\n",
    "\n",
    "# 데이터셋 인스턴스를 생성합니다.\n",
    "# window_size = 56\n",
    "# prediction_length = 28\n",
    "# korea_data = FinedustDataset(korea_data,window_size=window_size, prediction_length=prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EsrnzAji56ez"
   },
   "source": [
    "Transformer - 한국만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Timeseries Transformer 인코더 층 정의\n",
    "def timeseries_transformer_encoder(inputs, num_heads, key_dim, ff_dim, dropout_rate):\n",
    "    attention = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=key_dim, dropout=dropout_rate)(inputs, inputs)\n",
    "    attention = tf.keras.layers.Dropout(dropout_rate)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attention)\n",
    "    \n",
    "    ff = tf.keras.layers.Dense(ff_dim, activation='relu')(attention)\n",
    "    ff = tf.keras.layers.Dense(inputs.shape[-1])(ff)  # 입력과 동일한 크기로 설정\n",
    "    ff = tf.keras.layers.Dropout(dropout_rate)(ff)\n",
    "    return tf.keras.layers.LayerNormalization(epsilon=1e-6)(attention + ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 윈도우 크기, predicition_size 설정\n",
    "window_size = 30  # 윈도우 크기\n",
    "prediction_length = 7  # 예측하려는 시간 범위\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 1s 3ms/step - loss: 605.3649 - mae: 17.2852\n",
      "Test Set Mean Absolute Error: 17.28523826599121\n",
      "250/250 [==============================] - 1s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "removed_columns = ['TM', 'PM10', 'WW', 'CT']\n",
    "\n",
    "# 데이터 준비\n",
    "X = korea_data.drop(columns=removed_columns)\n",
    "X.fillna(X.mean(), inplace=True)  # 결측값 처리\n",
    "y = korea_data['PM10']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# 데이터 정규화 및 시퀀스\n",
    "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_val_seq = np.array([X_train_val_scaled[i:i+window_size] for i in range(len(X_train_val_scaled) - window_size - prediction_length + 1)])\n",
    "y_train_val_seq = np.array([y_train_val.values[i+window_size:i+window_size+prediction_length] for i in range(len(X_train_val_seq))])\n",
    "\n",
    "X_test_seq = np.array([X_test_scaled[i:i+window_size] for i in range(len(X_test_scaled) - window_size - prediction_length + 1)])\n",
    "y_test_seq = np.array([y_test.values[i+window_size:i+window_size+prediction_length] for i in range(len(X_test_seq))])\n",
    "\n",
    "# Transformer 모델 정의 및 구성\n",
    "input_dim = X_train_val_seq.shape[2]  # Feature dimension\n",
    "\n",
    "inputs = tf.keras.Input(shape=(window_size, X_train_val_seq.shape[2]))\n",
    "x = timeseries_transformer_encoder(inputs, num_heads=4, key_dim=64, ff_dim=128, dropout_rate=0.1)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(prediction_length)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 학습 및 평가\n",
    "history = model.fit(\n",
    "    X_train_val_seq, y_train_val_seq,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Set Mean Absolute Error: {test_mae}\")\n",
    "\n",
    "# 예측 (test_size, prediction_length)\n",
    "predictions = model.predict(X_test_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pred_1     pred_2     pred_3     pred_4     pred_5     pred_6  \\\n",
      "0  30.095184  30.886255  30.959536  31.761076  30.966103  31.675886   \n",
      "1  29.996330  30.786329  30.859476  31.662292  30.875843  31.582747   \n",
      "2  30.293821  31.116236  31.188841  31.960320  31.172642  31.895237   \n",
      "3  30.710398  31.585386  31.650015  32.383030  31.591175  32.329094   \n",
      "4  31.113224  32.041492  32.098732  32.793652  31.996870  32.751186   \n",
      "5  31.533499  32.513126  32.562763  33.220257  32.416763  33.186382   \n",
      "6  32.187664  33.211559  33.244652  33.865009  33.031746  33.815987   \n",
      "7  32.689610  33.673145  33.703785  34.326862  33.451538  34.208961   \n",
      "8  33.061996  34.060818  34.092365  34.692833  33.808407  34.551178   \n",
      "9  33.161102  34.194794  34.230717  34.802116  33.933777  34.679897   \n",
      "\n",
      "      pred_7  actual_1  actual_2  actual_3  actual_4  actual_5  actual_6  \\\n",
      "0  32.711861      44.0      41.0      48.0      59.0      63.0      66.0   \n",
      "1  32.617149      41.0      48.0      59.0      63.0      66.0      54.0   \n",
      "2  32.927906      48.0      59.0      63.0      66.0      54.0      40.0   \n",
      "3  33.359154      59.0      63.0      66.0      54.0      40.0      42.0   \n",
      "4  33.778751      63.0      66.0      54.0      40.0      42.0      29.0   \n",
      "5  34.211773      66.0      54.0      40.0      42.0      29.0      38.0   \n",
      "6  34.839474      54.0      40.0      42.0      29.0      38.0      24.0   \n",
      "7  35.237461      40.0      42.0      29.0      38.0      24.0      22.0   \n",
      "8  35.581005      42.0      29.0      38.0      24.0      22.0      32.0   \n",
      "9  35.705952      29.0      38.0      24.0      22.0      32.0      31.0   \n",
      "\n",
      "   actual_7  \n",
      "0      54.0  \n",
      "1      40.0  \n",
      "2      42.0  \n",
      "3      29.0  \n",
      "4      38.0  \n",
      "5      24.0  \n",
      "6      22.0  \n",
      "7      32.0  \n",
      "8      31.0  \n",
      "9      24.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예측,실제 값을 데이터프레임으로 변환\n",
    "pred_df = pd.DataFrame(predictions, columns=[f\"pred_{i+1}\" for i in range(prediction_length)])\n",
    "actual_df = pd.DataFrame(y_test_seq, columns=[f\"actual_{i+1}\" for i in range(prediction_length)])\n",
    "comparison_df = pd.concat([pred_df, actual_df], axis=1)\n",
    "\n",
    "# 일부 데이터 출력 (예: 상위 10개 행)\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# CSV 파일로 저장\n",
    "# comparison_df.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i2JfeR_QCJ9T"
   },
   "source": [
    "Transformer-중국포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9488, 111)\n",
      "VV             0.031619\n",
      "WD_yanan       0.021079\n",
      "WS_yanan       0.021079\n",
      "TA_yanan       0.105396\n",
      "TD_yanan       0.274030\n",
      "HM_yanan       0.685076\n",
      "PS_yanan       0.031619\n",
      "PR             0.063238\n",
      "VV_tongliao    0.010540\n",
      "WD_tongliao    0.010540\n",
      "WS_tongliao    0.010540\n",
      "TA_tongliao    0.137015\n",
      "TD_tongliao    0.252951\n",
      "HM_tongliao    0.242411\n",
      "PS_tongliao    0.010540\n",
      "PR_tongliao    0.010540\n",
      "VV_qingdao     0.094857\n",
      "WD_qingdao     0.115936\n",
      "WS_qingdao     0.115936\n",
      "TA_qingdao     0.094857\n",
      "TD_qingdao     0.200253\n",
      "HM_qingdao     0.790472\n",
      "PS_qingdao     0.094857\n",
      "PR_qingdao     0.094857\n",
      "VV_chifeng     0.063238\n",
      "WD_chifeng     0.021079\n",
      "WS_chifeng     0.063238\n",
      "TA_chifeng     0.115936\n",
      "TD_chifeng     0.263491\n",
      "HM_chifeng     0.179174\n",
      "PS_chifeng     0.031619\n",
      "PR_chifeng     0.021079\n",
      "TA_dalian      0.042159\n",
      "TD_dalian      0.242411\n",
      "HM_dalian      0.042159\n",
      "dtype: float64\n",
      "Index(['TM', 'STN', 'WD', 'WS', 'PA', 'PS', 'TA', 'TD', 'HM', 'PV',\n",
      "       ...\n",
      "       'TD_dalian', 'HM_dalian', 'PS_dalian', 'PT_dalian', 'PR_dalian',\n",
      "       'RH_dalian', 'PM10_dalian', 'LON_dalian', 'LAT_dalian', 'diff'],\n",
      "      dtype='object', length=111)\n",
      "                      TM    STN    WD   WS      PA      PS    TA    TD    HM  \\\n",
      "0    2018-01-01 00:00:00  108.0   0.0  0.0     0.0     0.0   0.0   0.0   0.0   \n",
      "1    2018-01-01 03:00:00  108.0   0.0  0.0     0.0     0.0   0.0   0.0   0.0   \n",
      "2    2018-01-01 06:00:00  108.0   0.0  0.0     0.0     0.0   0.0   0.0   0.0   \n",
      "3    2018-01-01 09:00:00  108.0   0.0  0.0     0.0     0.0   0.0   0.0   0.0   \n",
      "4    2018-01-01 12:00:00  108.0   0.0  0.0     0.0     0.0   0.0   0.0   0.0   \n",
      "...                  ...    ...   ...  ...     ...     ...   ...   ...   ...   \n",
      "9483 2022-09-07 03:00:00  108.0  25.0  3.4  1003.1  1013.0  20.7  17.7  83.0   \n",
      "9484 2022-09-07 06:00:00  108.0  29.0  1.5  1005.3  1015.3  18.6  17.6  94.0   \n",
      "9485 2022-09-07 09:00:00  108.0   2.0  2.0  1007.2  1017.1  21.6  18.1  81.0   \n",
      "9486 2022-09-07 12:00:00  108.0  23.0  2.5  1007.4  1017.2  25.9   9.6  36.0   \n",
      "9487 2022-09-07 15:00:00  108.0  25.0  2.2  1006.5  1016.2  27.8  12.1  38.0   \n",
      "\n",
      "        PV  ... TD_dalian  HM_dalian  PS_dalian PT_dalian  PR_dalian  \\\n",
      "0      0.0  ...      -9.2       52.1     1028.3       2.0        1.6   \n",
      "1      0.0  ...     -10.1       42.9     1028.9       2.0        0.6   \n",
      "2      0.0  ...     -10.1       42.9     1028.9       2.0        0.6   \n",
      "3      0.0  ...     -17.6       25.0     1027.6       2.0        0.2   \n",
      "4      0.0  ...     -16.3       31.1     1029.1       2.0        1.4   \n",
      "...    ...  ...       ...        ...        ...       ...        ...   \n",
      "9483  20.2  ...      15.2       56.2     1016.8       2.0        2.0   \n",
      "9484  20.1  ...       6.8       24.0     1016.6       7.0        0.8   \n",
      "9485  20.8  ...      14.3       44.1     1016.9       2.0        0.2   \n",
      "9486  11.9  ...      15.9       65.9     1018.3       2.0        1.4   \n",
      "9487  14.1  ...      12.3       56.1     1018.8       2.0        0.5   \n",
      "\n",
      "      RH_dalian  PM10_dalian  LON_dalian  LAT_dalian  diff  \n",
      "0           0.0         49.0      121.63        38.9   3.0  \n",
      "1           0.0         94.0      121.63        38.9   3.0  \n",
      "2           0.0         94.0      121.63        38.9   3.0  \n",
      "3           0.0        120.0      121.63        38.9   3.0  \n",
      "4           0.0         30.0      121.63        38.9   3.0  \n",
      "...         ...          ...         ...         ...   ...  \n",
      "9483        2.0         29.0      121.63        38.9   3.0  \n",
      "9484        2.0         21.0      121.63        38.9   3.0  \n",
      "9485        2.0          4.0      121.63        38.9   3.0  \n",
      "9486        2.0         13.0      121.63        38.9   3.0  \n",
      "9487        2.0          6.0      121.63        38.9   3.0  \n",
      "\n",
      "[9488 rows x 111 columns]\n"
     ]
    }
   ],
   "source": [
    "korea_data = pd.read_csv(path)\n",
    "china_data = concat_china_data(korea_data)\n",
    "\n",
    "china_data = convert_timesteps(china_data)\n",
    "print_missing_info(china_data)\n",
    "\n",
    "print(china_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59/59 [==============================] - 0s 4ms/step - loss: 803.3805 - mae: 21.3715\n",
      "Test Set Mean Absolute Error: 21.371501922607422\n",
      "59/59 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "removed_columns = ['TM', 'PM10', 'WW', 'CT']\n",
    "\n",
    "# 데이터 준비\n",
    "X = china_data.drop(columns=removed_columns)\n",
    "X.fillna(X.mean(), inplace=True)  # 결측값 처리\n",
    "y = china_data['PM10']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# 데이터 정규화 및 시퀀스\n",
    "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_val_seq = np.array([X_train_val_scaled[i:i+window_size] for i in range(len(X_train_val_scaled) - window_size - prediction_length + 1)])\n",
    "y_train_val_seq = np.array([y_train_val.values[i+window_size:i+window_size+prediction_length] for i in range(len(X_train_val_seq))])\n",
    "\n",
    "X_test_seq = np.array([X_test_scaled[i:i+window_size] for i in range(len(X_test_scaled) - window_size - prediction_length + 1)])\n",
    "y_test_seq = np.array([y_test.values[i+window_size:i+window_size+prediction_length] for i in range(len(X_test_seq))])\n",
    "\n",
    "# Transformer 모델 정의 및 구성\n",
    "input_dim = X_train_val_seq.shape[2]  # Feature dimension\n",
    "\n",
    "inputs = tf.keras.Input(shape=(window_size, X_train_val_seq.shape[2]))\n",
    "x = timeseries_transformer_encoder(inputs, num_heads=4, key_dim=64, ff_dim=128, dropout_rate=0.1)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(prediction_length)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# 학습 및 평가\n",
    "history = model.fit(\n",
    "    X_train_val_seq, y_train_val_seq,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "test_loss, test_mae = model.evaluate(X_test_seq, y_test_seq)\n",
    "print(f\"Test Set Mean Absolute Error: {test_mae}\")\n",
    "\n",
    "# 예측 (test_size, prediction_length)\n",
    "predictions = model.predict(X_test_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      pred_1     pred_2     pred_3     pred_4     pred_5     pred_6  \\\n",
      "0  14.306901  12.963779  12.793951  14.224319  14.885900  14.158140   \n",
      "1  13.580867  12.232352  12.011200  13.515442  14.183243  13.576749   \n",
      "2  11.594143  10.376992   9.816342  11.528031  12.357327  11.953491   \n",
      "3  13.468301  12.247033  11.899059  13.344338  14.191192  13.270462   \n",
      "4  13.439093  12.219550  11.862348  13.311944  14.168741  13.241842   \n",
      "5  13.668106  12.439092  12.128189  13.551778  14.377426  13.447536   \n",
      "6  13.468888  12.312323  11.965425  13.420453  14.238415  13.311279   \n",
      "7  13.988493  12.801726  12.568789  13.963269  14.712805  13.758474   \n",
      "8  14.531341  13.295014  13.187711  14.508088  15.192886  14.210098   \n",
      "9  31.642080  28.832083  30.563902  30.711941  29.940981  28.497238   \n",
      "\n",
      "      pred_7  actual_1  actual_2  actual_3  actual_4  actual_5  actual_6  \\\n",
      "0  13.431527       8.0      14.0      18.0       7.0      16.0      12.0   \n",
      "1  12.729303      14.0      18.0       7.0      16.0      12.0       3.0   \n",
      "2  10.874639      18.0       7.0      16.0      12.0       3.0       2.0   \n",
      "3  12.513659       7.0      16.0      12.0       3.0       2.0      19.0   \n",
      "4  12.487044      16.0      12.0       3.0       2.0      19.0      25.0   \n",
      "5  12.718049      12.0       3.0       2.0      19.0      25.0      27.0   \n",
      "6  12.624067       3.0       2.0      19.0      25.0      27.0      20.0   \n",
      "7  13.132023       2.0      19.0      25.0      27.0      20.0      22.0   \n",
      "8  13.638468      19.0      25.0      27.0      20.0      22.0      10.0   \n",
      "9  29.265083      25.0      27.0      20.0      22.0      10.0       1.0   \n",
      "\n",
      "   actual_7  \n",
      "0       3.0  \n",
      "1       2.0  \n",
      "2      19.0  \n",
      "3      25.0  \n",
      "4      27.0  \n",
      "5      20.0  \n",
      "6      22.0  \n",
      "7      10.0  \n",
      "8       1.0  \n",
      "9      18.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예측,실제 값을 데이터프레임으로 변환\n",
    "pred_df = pd.DataFrame(predictions, columns=[f\"pred_{i+1}\" for i in range(prediction_length)])\n",
    "actual_df = pd.DataFrame(y_test_seq, columns=[f\"actual_{i+1}\" for i in range(prediction_length)])\n",
    "comparison_df = pd.concat([pred_df, actual_df], axis=1)\n",
    "\n",
    "# 일부 데이터 출력 (예: 상위 10개 행)\n",
    "print(comparison_df.head(10))\n",
    "\n",
    "# CSV 파일로 저장\n",
    "comparison_df.to_csv('predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
